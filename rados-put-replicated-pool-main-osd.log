2015-11-23 08:48:50.467007 7f6f574e6700  5 osd.0 30 tick
2015-11-23 08:48:50.467035 7f6f574e6700 20 osd.0 30 scrub_should_schedule should run between 0 - 24 now 8 = yes
2015-11-23 08:48:50.467065 7f6f574e6700 20 osd.0 30 scrub_should_schedule loadavg 0 < max 0.5 = yes
2015-11-23 08:48:50.467075 7f6f574e6700 20 osd.0 30 sched_scrub load_is_low=1
2015-11-23 08:48:50.467077 7f6f574e6700 10 osd.0 30 sched_scrub 0.0 at 2015-11-22 14:30:18.368406: 65912.1 < min (86400 seconds)
2015-11-23 08:48:50.467084 7f6f574e6700 20 osd.0 30 sched_scrub done
2015-11-23 08:48:50.467085 7f6f574e6700 10 osd.0 30 do_waiters -- start
2015-11-23 08:48:50.467086 7f6f574e6700 10 osd.0 30 do_waiters -- finish
2015-11-23 08:48:50.603401 7f6f3a74c700 10 osd.0 30  new session 0x7f6f66772a00 con=0x7f6f66884680 addr=10.253.0.2:0/1007850
2015-11-23 08:48:50.603453 7f6f3a74c700 10 osd.0 30  session 0x7f6f66772a00 client.admin has caps osdcap[grant(*)] 'allow *'
2015-11-23 08:48:50.616647 7f6f3a74c700 20 osd.0 30 should_share_map client.4141 10.253.0.2:0/1007850 30
2015-11-23 08:48:50.616725 7f6f3a74c700 15 osd.0 30 enqueue_op 0x7f6f64d2bc00 prio 63 cost 4194304 latency 0.010409 osd_op(client.4141.0:1 t2.dat [writefull 0~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5
2015-11-23 08:48:50.616774 7f6f4336f700 10 osd.0 30 dequeue_op 0x7f6f64d2bc00 prio 63 cost 4194304 latency 0.010457 osd_op(client.4141.0:1 t2.dat [writefull 0~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5 pg pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean]
2015-11-23 08:48:50.616791 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] op_has_sufficient_caps pool=1 (simple ) owner=0 need_read_cap=0 need_write_cap=1 need_class_read_cap=0 need_class_write_cap=0 -> yes
2015-11-23 08:48:50.616798 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] handle_message: 0x7f6f64d2bc00
2015-11-23 08:48:50.616803 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] do_op osd_op(client.4141.0:1 t2.dat [writefull 0~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5 may_write -> write-ordered flags ondisk+write+known_if_redirected
2015-11-23 08:48:50.616847 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] get_object_context: obc NOT found in cache: a3002fad/t2.dat/head//1
2015-11-23 08:48:50.616855 7f6f4336f700 15 filestore(/var/lib/ceph/osd/ceph-0) getattr 1.2d_head/a3002fad/t2.dat/head//1 '_'
##
## FileStore.cc:288     int FileStore::lfn_open(coll_t, const ghobject_t &, bool, FDRef *, Index *)
## FileStore.cc:3878    int FileStore::getattr(coll_t, const ghobject_t &, const char *, bufferptr &)
## ObjectStore.h:1931   int ObjectStore::getattr(coll_t, const ghobject_t &, const string &, bufferlist &)
## PGBackend.cc:190     int PGBackend::objects_get_attr(const hobject_t &, const string &, bufferlist *)
## ReplicatedPG.cc:7746 ObjectContextRef ReplicatedPG::get_object_context(const hobject_t &, bool, map<string, bufferlist> *)
## ReplicatedPG.cc:7877 int ReplicatedPG::find_object_context(const hobject_t &, ObjectContextRef *, bool, bool, hobject_t *)
## ReplicatedPG.cc:1494 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.617037 7f6f4336f700 10 filestore(/var/lib/ceph/osd/ceph-0) error opening file /var/lib/ceph/osd/ceph-0/current/1.2d_head/t2.dat__head_A3002FAD__1 with flags=2: (2) No such file or directory
2015-11-23 08:48:50.617046 7f6f4336f700 10 filestore(/var/lib/ceph/osd/ceph-0) getattr 1.2d_head/a3002fad/t2.dat/head//1 '_' = -2
2015-11-23 08:48:50.617052 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] get_object_context: no obc for soid a3002fad/t2.dat/head//1 but can_create
2015-11-23 08:48:50.617065 7f6f4336f700 15 filestore(/var/lib/ceph/osd/ceph-0) getattr 1.2d_head/a3002fad/t2.dat/head//1 'snapset'
##
## FileStore.cc:288     int FileStore::lfn_open(coll_t, const ghobject_t &, bool, FDRef *, Index *)
## FileStore.cc:3878    int FileStore::getattr(coll_t, const ghobject_t &, const char *, bufferptr &)
## ObjectStore.h:1931   int ObjectStore::getattr(coll_t, const ghobject_t &, const string &, bufferlist &)
## PGBackend.cc:190     int PGBackend::objects_get_attr(const hobject_t &, const string &, bufferlist *)
## ReplicatedPG.cc:8151 SnapSetContext* ReplicatedPG::get_snapset_context(const hobject_t &, bool, map<string, bufferlist> *)
## ReplicatedPG.cc:7760 ObjectContextRef ReplicatedPG::get_object_context(const hobject_t &, bool, map<string, bufferlist> *)
## ReplicatedPG.cc:7877 int ReplicatedPG::find_object_context(const hobject_t &, ObjectContextRef *, bool, bool, hobject_t *)
## ReplicatedPG.cc:1494 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.617076 7f6f4336f700 10 filestore(/var/lib/ceph/osd/ceph-0) error opening file /var/lib/ceph/osd/ceph-0/current/1.2d_head/t2.dat__head_A3002FAD__1 with flags=2: (2) No such file or directory
2015-11-23 08:48:50.617079 7f6f4336f700 10 filestore(/var/lib/ceph/osd/ceph-0) getattr 1.2d_head/a3002fad/t2.dat/head//1 'snapset' = -2
2015-11-23 08:48:50.617080 7f6f4336f700 15 filestore(/var/lib/ceph/osd/ceph-0) getattr 1.2d_head/a3002fad/t2.dat/snapdir//1 'snapset'
2015-11-23 08:48:50.617095 7f6f4336f700 10 filestore(/var/lib/ceph/osd/ceph-0) error opening file /var/lib/ceph/osd/ceph-0/current/1.2d_head/t2.dat__snapdir_A3002FAD__1 with flags=2: (2) No such file or directory
2015-11-23 08:48:50.617097 7f6f4336f700 10 filestore(/var/lib/ceph/osd/ceph-0) getattr 1.2d_head/a3002fad/t2.dat/snapdir//1 'snapset' = -2
##
## ReplicatedPG.cc:7716 ObjectContextRef ReplicatedPG::create_object_context(const object_info_t &, SnapSetContext *)
## ReplicatedPG.cc:7763 ObjectContextRef ReplicatedPG::get_object_context(const hobject_t &, bool, map<string, bufferlist> *)
## ReplicatedPG.cc:7853 int ReplicatedPG::find_object_context(const hobject_t &, ObjectContextRef *, bool, bool, hobject_t *)
## ReplicatedPG.cc:1494 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.617112 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] create_object_context 0x7f6f65725e40 a3002fad/t2.dat/head//1 
##
## ReplicatedPG.cc:7615 void ReplicatedPG::populate_obc_watchers(ObjectContextRef)
## ReplicatedPG.cc:7718 ObjectContextRef ReplicatedPG::create_object_context(const object_info_t &, SnapSetContext *)
## ReplicatedPG.cc:7763 ObjectContextRef ReplicatedPG::get_object_context(const hobject_t &, bool, map<string, bufferlist> *)
## ReplicatedPG.cc:7853 int ReplicatedPG::find_object_context(const hobject_t &, ObjectContextRef *, bool, bool, hobject_t *)
## ReplicatedPG.cc:1494 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.617119 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] populate_obc_watchers a3002fad/t2.dat/head//1
##
## ReplicatedPG.cc:7585 void ReplicatedPG::check_blacklisted_obc_watchers(ObjectContextRef)
## ReplicatedPG.cc:7636 void ReplicatedPG::populate_obc_watchers(ObjectContextRef)
## ReplicatedPG.cc:7718 ObjectContextRef ReplicatedPG::create_object_context(const object_info_t &, SnapSetContext *)
## ReplicatedPG.cc:7763 ObjectContextRef ReplicatedPG::get_object_context(const hobject_t &, bool, map<string, bufferlist> *)
## ReplicatedPG.cc:7853 int ReplicatedPG::find_object_context(const hobject_t &, ObjectContextRef *, bool, bool, hobject_t *)
## ReplicatedPG.cc:1494 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.617124 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] ReplicatedPG::check_blacklisted_obc_watchers for obc a3002fad/t2.dat/head//1
##
## ReplicatedPG.cc:7764 ObjectContextRef ReplicatedPG::get_object_context(const hobject_t &, bool, map<string, bufferlist> *)
## ReplicatedPG.cc:7853 int ReplicatedPG::find_object_context(const hobject_t &, ObjectContextRef *, bool, bool, hobject_t *)
## ReplicatedPG.cc:1494 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.617128 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] get_object_context: 0x7f6f65725e40 a3002fad/t2.dat/head//1 rwstate(none n=0 w=0) oi: a3002fad/t2.dat/head//1(0'0 unknown.0.0:0 wrlock_by=unknown.0.0:0 s 0 uv 0) ssc: 0x7f6f64d23fe0 snapset: 0=[]:[]
##
## ReplicatedPG.cc:7855 int ReplicatedPG::find_object_context(const hobject_t &, ObjectContextRef *, bool, bool, hobject_t *)
## ReplicatedPG.cc:1494 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.617135 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] find_object_context a3002fad/t2.dat/head//1 @head oi=a3002fad/t2.dat/head//1(0'0 unknown.0.0:0 wrlock_by=unknown.0.0:0 s 0 uv 0)
2015-11-23 08:48:50.617152 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] get_object_context: obc NOT found in cache: a3002fad/t2.dat/snapdir//1
2015-11-23 08:48:50.617156 7f6f4336f700 15 filestore(/var/lib/ceph/osd/ceph-0) getattr 1.2d_head/a3002fad/t2.dat/snapdir//1 '_'
2015-11-23 08:48:50.617165 7f6f4336f700 10 filestore(/var/lib/ceph/osd/ceph-0) error opening file /var/lib/ceph/osd/ceph-0/current/1.2d_head/t2.dat__snapdir_A3002FAD__1 with flags=2: (2) No such file or directory
2015-11-23 08:48:50.617167 7f6f4336f700 10 filestore(/var/lib/ceph/osd/ceph-0) getattr 1.2d_head/a3002fad/t2.dat/snapdir//1 '_' = -2
2015-11-23 08:48:50.617168 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] get_object_context: no obc for soid a3002fad/t2.dat/snapdir//1 and !can_create
##
## ReplicatedPG.cc:2189 void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.617182 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] execute_ctx 0x7f6f651cd200
##
## ReplicatedPG.cc:2226 void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.617191 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] do_op a3002fad/t2.dat/head//1 [writefull 0~4194304] ov 0'0 av 30'1 snapc 0=[] snapset 0=[]:[]
##
## ReplicatedPG.cc:3332 int ReplicatedPG::do_osd_ops(OpContext *, vector<OSDOp> &)
## ReplicatedPG.cc:5640 int ReplicatedPG::prepare_transaction(OpContext *)
## ReplicatedPG.cc:2258 void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.617201 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] do_osd_op a3002fad/t2.dat/head//1 [writefull 0~4194304]
##
## ReplicatedPG.cc:3344 int ReplicatedPG::do_osd_ops(OpContext *, vector<OSDOp> &)
## ReplicatedPG.cc:5640 int ReplicatedPG::prepare_transaction(OpContext *)
## ReplicatedPG.cc:2258 void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.617204 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] do_osd_op  writefull 0~4194304
##
## ReplicatedPG.cc:5337 void ReplicatedPG::make_writeable(OpContext *)
## ReplicatedPG.cc:5652 int ReplicatedPG::prepare_transaction(OpContext *)
## ReplicatedPG.cc:2258 void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.619072 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] make_writeable a3002fad/t2.dat/head//1 snapset=0x7f6f64d24020  snapc=0=[]
##
## ReplicatedPG.cc:5350 void ReplicatedPG::make_writeable(OpContext *)
## ReplicatedPG.cc:5652 int ReplicatedPG::prepare_transaction(OpContext *)
## ReplicatedPG.cc:2258 void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.619076 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean]  setting DIRTY flag
##
## ReplicatedPG.cc:5485 void ReplicatedPG::make_writeable(OpContext *)
## ReplicatedPG.cc:5652 int ReplicatedPG::prepare_transaction(OpContext *)
## ReplicatedPG.cc:2258 void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.619083 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] make_writeable a3002fad/t2.dat/head//1 done, snapset=0=[]:[]+head
##
## ReplicatedPG.cc:5665 void ReplicatedPG::finish_ctx(OpContext *, int, bool, bool)
## ReplicatedPG.cc:5654 int ReplicatedPG::prepare_transaction(OpContext *)
## ReplicatedPG.cc:2258 void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.619087 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] finish_ctx a3002fad/t2.dat/head//1 0x7f6f651cd200 op modify  
##
## ReplicatedPG.cc:5776 void ReplicatedPG::finish_ctx(OpContext *, int, bool, bool)
## ReplicatedPG.cc:5654 int ReplicatedPG::prepare_transaction(OpContext *)
## ReplicatedPG.cc:2258 void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.619094 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean]  set mtime to 2015-11-23 08:48:50.476478
##
## ReplicatedPG.cc:5787 void ReplicatedPG::finish_ctx(OpContext *, int, bool, bool)
## ReplicatedPG.cc:5654 int ReplicatedPG::prepare_transaction(OpContext *)
## ReplicatedPG.cc:2258 void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.619106 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=0 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean]  final snapset 0=[]:[]+head in a3002fad/t2.dat/head//1
##
## ReplicatedPG.cc:2309 void ReplicatedPG::execute_ctx(OpContext *)  // error handling happens here
## ReplicatedPG.cc:1750 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.619115 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean]  zeroing write result code 0
##
## ReplicatedPG.cc:7488 ReplicatedPG::RepGather *ReplicatedPG::new_repop(OpContext *, ObjectContextRef, ceph_tid_t)
## ReplicatedPG.cc:2359 void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.619121 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] new_repop rep_tid 1901 on osd_op(client.4141.0:1 t2.dat [writefull 0~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5
##
## ReplicatedPG.cc:7421 void ReplicatedPG::issue_repop(RepGather *)
##
## // sets callbacks:
## //      onapplied_sync: C_OSD_OndiskWriteUnlock::finish(), unlock obc (think of inode) disk write lock
## //      on_all_applied: void ReplicatedPG::repop_all_applied(RepGather *)
## //      on_all_commit: void ReplicatedPG::repop_all_committed(RepGather *)
##
## ReplicatedPG.cc:2364 void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750 void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296 void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.619131 7f6f4336f700  7 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] issue_repop rep_tid 1901 o a3002fad/t2.dat/head//1
2015-11-23 08:48:50.619182 7f6f4336f700 20 osd.0 30 share_map_peer 0x7f6f64eb9440 already has epoch 30
2015-11-23 08:48:50.620395 7f6f4336f700 20 osd.0 30 share_map_peer 0x7f6f65173080 already has epoch 30
##
## PG.cc:2957               void PG::append_log(const vector<pg_log_entry_t> &, eversion_t, eversion_t, ObjectStore::Transaction &, bool)
## ReplicatedPG.h:389       void ReplicatedPG::log_operation(const vector<pg_log_entry_t> &, boost::optional<pg_hit_set_history_t> &, const eversion_t &, const eversion_t &, bool, ObjectStore::Transaction *)
## ReplicatedBackend.cc:611 void ReplicatedBackend::submit_transaction(const hobject_t &, const eversion_t &, PGTransaction *, const eversion_t &, const eversion_t &, const vector<pg_log_entry_t> &, Context *, Context *, Context *, ceph_tid_t, osd_reqid_t, OpRequestRef)
## ReplicatedPG.cc:7467     void ReplicatedPG::issue_repop(RepGather *)
## ReplicatedPG.cc:2364     void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750     void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296     void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438              void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332              void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.620422 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( empty local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 mlcod 0'0 active+clean] append_log log((0'0,0'0], crt=0'0) [30'1 (0'0) modify   a3002fad/t2.dat/head//1 by client.4141.0:1 2015-11-23 08:48:50.476478]
##
## PG.cc:2933               void PG::add_log_entry(const pg_log_entry_t &, bufferlist &)
## PG.cc:2963               void PG::append_log(const vector<pg_log_entry_t> &, eversion_t, eversion_t, ObjectStore::Transaction &, bool)
## ReplicatedPG.h:389       void ReplicatedPG::log_operation(const vector<pg_log_entry_t> &, boost::optional<pg_hit_set_history_t> &, const eversion_t &, const eversion_t &, bool, ObjectStore::Transaction *)
## ReplicatedBackend.cc:611 void ReplicatedBackend::submit_transaction(const hobject_t &, const eversion_t &, PGTransaction *, const eversion_t &, const eversion_t &, const vector<pg_log_entry_t> &, Context *, Context *, Context *, ceph_tid_t, osd_reqid_t, OpRequestRef)
## ReplicatedPG.cc:7467     void ReplicatedPG::issue_repop(RepGather *)
## ReplicatedPG.cc:2364     void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750     void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296     void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438              void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332              void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.620455 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 lua=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] add_log_entry 30'1 (0'0) modify   a3002fad/t2.dat/head//1 by client.4141.0:1 2015-11-23 08:48:50.476478
##
##
## PG.cc:2985               void PG::append_log(const vector<pg_log_entry_t> &, eversion_t, eversion_t, ObjectStore::Transaction &, bool)
## ReplicatedPG.h:389       void ReplicatedPG::log_operation(const vector<pg_log_entry_t> &, boost::optional<pg_hit_set_history_t> &, const eversion_t &, const eversion_t &, bool, ObjectStore::Transaction *)
## ReplicatedBackend.cc:611 void ReplicatedBackend::submit_transaction(const hobject_t &, const eversion_t &, PGTransaction *, const eversion_t &, const eversion_t &, const vector<pg_log_entry_t> &, Context *, Context *, Context *, ceph_tid_t, osd_reqid_t, OpRequestRef)
## ReplicatedPG.cc:7467     void ReplicatedPG::issue_repop(RepGather *)
## ReplicatedPG.cc:2364     void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750     void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296     void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438              void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332              void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.620469 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 lua=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] append_log  adding 1 keys
##
## PG.cc:2990               void PG::append_log(const vector<pg_log_entry_t> &, eversion_t, eversion_t, ObjectStore::Transaction &, bool)
## ReplicatedPG.h:389       void ReplicatedPG::log_operation(const vector<pg_log_entry_t> &, boost::optional<pg_hit_set_history_t> &, const eversion_t &, const eversion_t &, bool, ObjectStore::Transaction *)
## ReplicatedBackend.cc:611 void ReplicatedBackend::submit_transaction(const hobject_t &, const eversion_t &, PGTransaction *, const eversion_t &, const eversion_t &, const vector<pg_log_entry_t> &, Context *, Context *, Context *, ceph_tid_t, osd_reqid_t, OpRequestRef)
## ReplicatedPG.cc:7467     void ReplicatedPG::issue_repop(RepGather *)
## ReplicatedPG.cc:2364     void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750     void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296     void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438              void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332              void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.620495 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 lua=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] append_log: trimming to 0'0 entries 
##
## PGLog.cc:745             void PGLog::write_log(ObjectStore::Transaction &, const coll_t &, const ghobject_t &)
## PG.cc:2887               void PG::write_if_dirty(ObjectStore::Transaction &)
## PG.cc:2996               void PG::append_log(const vector<pg_log_entry_t> &, eversion_t, eversion_t, ObjectStore::Transaction &, bool)
## ReplicatedPG.h:389       void ReplicatedPG::log_operation(const vector<pg_log_entry_t> &, boost::optional<pg_hit_set_history_t> &, const eversion_t &, const eversion_t &, bool, ObjectStore::Transaction *)
## ReplicatedBackend.cc:611 void ReplicatedBackend::submit_transaction(const hobject_t &, const eversion_t &, PGTransaction *, const eversion_t &, const eversion_t &, const vector<pg_log_entry_t> &, Context *, Context *, Context *, ceph_tid_t, osd_reqid_t, OpRequestRef)
## ReplicatedPG.cc:7467     void ReplicatedPG::issue_repop(RepGather *)
## ReplicatedPG.cc:2364     void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750     void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296     void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438              void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332              void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.620510 7f6f4336f700 10 write_log with: dirty_to: 0'0, dirty_from: 4294967295'18446744073709551615, dirty_divergent_priors: 0, writeout_from: 30'1, trimmed: 
##
## FileStore.cc:1872        int FileStore::queue_transactions(Sequencer *, list<Transaction *> &, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
##
## // wraps callbacks set by ReplicatedPG::queue_transaction
## // onreadable      <- on_applied     <- ReplicatedBackend::op_applied(InProgressOp *) <- ReplicatedPG::repop_all_applied(RepGather *)
## // onreadable_sync <- onapplied_sync <- C_OSD_OndiskWriteUnlock::finish(int)
## // ondisk          <- on_commit      <- ReplicatedBackend::op_commit(InProgressOp *) <- ReplicatedPG::repop_all_committed(RepGather *)
##
## ObjectStore.h:1711       int ObjectStore::queue_transactions(Sequencer *, list<Transaction *> &, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ObjectStore.h:1698       int ObjectStore::queue_transaction(Sequencer *, Transaction *, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ReplicatedPG.h:329       void ReplicatedPG::queue_transaction(ObjectStore::Transaction *, OpRequestRef)
##
## // sets callbacks:
## //      on_commit  void ReplicatedBackend::op_commit(InProgressOp *),
## //           wraps void ReplicatedPG::repop_all_committed(RepGather *)
## //      on_applied void ReplicatedBackend::op_applied(InProgressOp *),
## //           wraps void ReplicatedPG::repop_all_applied(RepGather *)
## //      on_applied_sync void C_OSD_OndiskWriteUnlock::finish(int)
##
## ReplicatedBackend.cc:632 void ReplicatedBackend::submit_transaction(const hobject_t &, const eversion_t &, PGTransaction *, const eversion_t &, const eversion_t &, const vector<pg_log_entry_t> &, Context *, Context *, Context *, ceph_tid_t, osd_reqid_t, OpRequestRef)
## ReplicatedPG.cc:7467     void ReplicatedPG::issue_repop(RepGather *)
## ReplicatedPG.cc:2364     void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750     void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296     void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438              void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332              void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.620524 7f6f4336f700  5 filestore(/var/lib/ceph/osd/ceph-0) queue_transactions existing osr(1.2d 0x7f6f64cfdee0)/0x7f6f64cfdee0
##
## JournalingObjectStore.cc:160 uint64_t JournalingObjectStore::SubmitManager::op_submit_start()
## FileStore.cc:1889            int FileStore::queue_transactions(Sequencer *, list<Transaction *> &, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ObjectStore.h:1711		int ObjectStore::queue_transactions(Sequencer *, list<Transaction *> &, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ObjectStore.h:1698		int ObjectStore::queue_transaction(Sequencer *, Transaction *, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ReplicatedPG.h:329		void ReplicatedPG::queue_transaction(ObjectStore::Transaction *, OpRequestRef)
## ReplicatedBackend.cc:632	void ReplicatedBackend::submit_transaction(const hobject_t &, const eversion_t &, PGTransaction *, const eversion_t &, const eversion_t &, const vector<pg_log_entry_t> &, Context *, Context *, Context *, ceph_tid_t, osd_reqid_t, OpRequestRef)
## ReplicatedPG.cc:7467		void ReplicatedPG::issue_repop(RepGather *)
## ReplicatedPG.cc:2364		void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750		void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296		void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438			void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332			void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.620531 7f6f4336f700 10 journal op_submit_start 2665
##
## FileStore.cc:1903            int FileStore::queue_transactions(Sequencer *, list<Transaction *> &, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ObjectStore.h:1711		int ObjectStore::queue_transactions(Sequencer *, list<Transaction *> &, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ObjectStore.h:1698		int ObjectStore::queue_transaction(Sequencer *, Transaction *, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ReplicatedPG.h:329		void ReplicatedPG::queue_transaction(ObjectStore::Transaction *, OpRequestRef)
## ReplicatedBackend.cc:632	void ReplicatedBackend::submit_transaction(const hobject_t &, const eversion_t &, PGTransaction *, const eversion_t &, const eversion_t &, const vector<pg_log_entry_t> &, Context *, Context *, Context *, ceph_tid_t, osd_reqid_t, OpRequestRef)
## ReplicatedPG.cc:7467		void ReplicatedPG::issue_repop(RepGather *)
## ReplicatedPG.cc:2364		void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750		void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296		void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438			void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332			void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.620532 7f6f4336f700  5 filestore(/var/lib/ceph/osd/ceph-0) queue_transactions (writeahead) 2665 0x7f6f657e0d80
##
## JournalingObjectStore.cc:257 void JournalingObjectStore::_op_journal_transactions(list<ObjectStore::Transaction *> &, uint64_t, Context *, TrackedOpRef)
## FileStore.cc:1907            int FileStore::queue_transactions(Sequencer *, list<Transaction *> &, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
##
## // callback: FileStore::_journaled_ahead(Sequencer *, Op *, Context *)
## // which wraps ondisk = on_commit <- ReplicatedBackend::op_commit(InProgressOp *) <- ReplicatedPG::repop_all_committed(RepGather *)
## // Op contains:
## // onreadable <- on_applied <- ReplicatedBackend::op_applied(InProgressOp *) <- ReplicatedPG::repop_all_applied(RepGather *)
## // onreadable_sync <- onapplied_sync <- C_OSD_OndiskWriteUnlock::finish(int)
##
## ObjectStore.h:1711		int ObjectStore::queue_transactions(Sequencer *, list<Transaction *> &, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ObjectStore.h:1698		int ObjectStore::queue_transaction(Sequencer *, Transaction *, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ReplicatedPG.h:329		void ReplicatedPG::queue_transaction(ObjectStore::Transaction *, OpRequestRef)
## ReplicatedBackend.cc:632	void ReplicatedBackend::submit_transaction(const hobject_t &, const eversion_t &, PGTransaction *, const eversion_t &, const eversion_t &, const vector<pg_log_entry_t> &, Context *, Context *, Context *, ceph_tid_t, osd_reqid_t, OpRequestRef)
## ReplicatedPG.cc:7467		void ReplicatedPG::issue_repop(RepGather *)
## ReplicatedPG.cc:2364		void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750		void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296		void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438			void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332			void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.620533 7f6f4336f700 10 journal op_journal_transactions 2665 0x7f6f657e0d80
##
## FileJournal.cc:1494          void FileJournal::submit_entry(uint64_t, bufferlist&, int, Context *, TrackedOpRef) // transactions reach the journal queue, journal thread signaled
##
## // callback: onjournal = FileJournal::_journaled_ahead(OpSequencer *, Op *, Context *)
##    with a nested callback: ondisk <- oncommit = void ReplicatedPG::repop_all_committed(RepGather *)
##    The latter will be invoked by a dedicated thread (ondisk_finisher)
##
## JournalingObjectStore.cc:273 void JournalingObjectStore::_op_journal_transactions(list<ObjectStore::Transaction *> &, uint64_t, Context *, TrackedOpRef)
## FileStore.cc:1907            int FileStore::queue_transactions(Sequencer *, list<Transaction *> &, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ObjectStore.h:1711		int ObjectStore::queue_transactions(Sequencer *, list<Transaction *> &, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ObjectStore.h:1698		int ObjectStore::queue_transaction(Sequencer *, Transaction *, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ReplicatedPG.h:329		void ReplicatedPG::queue_transaction(ObjectStore::Transaction *, OpRequestRef)
## ReplicatedBackend.cc:632	void ReplicatedBackend::submit_transaction(const hobject_t &, const eversion_t &, PGTransaction *, const eversion_t &, const eversion_t &, const vector<pg_log_entry_t> &, Context *, Context *, Context *, ceph_tid_t, osd_reqid_t, OpRequestRef)
## ReplicatedPG.cc:7467		void ReplicatedPG::issue_repop(RepGather *)
## ReplicatedPG.cc:2364		void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750		void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296		void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438			void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332			void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.620545 7f6f4336f700  5 journal submit_entry seq 2665 len 4196455 (0x7f6f66cb5450)
##
## JournalingObjectStore.cc:166 void JournalingObjectStore::SubmitManager::op_submit_finish(uint64_t)
## FileStore.cc:1913            int FileStore::queue_transactions(Sequencer *, list<Transaction *> &, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ObjectStore.h:1711		int ObjectStore::queue_transactions(Sequencer *, list<Transaction *> &, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ObjectStore.h:1698		int ObjectStore::queue_transaction(Sequencer *, Transaction *, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
## ReplicatedPG.h:329		void ReplicatedPG::queue_transaction(ObjectStore::Transaction *, OpRequestRef)
## ReplicatedBackend.cc:632	void ReplicatedBackend::submit_transaction(const hobject_t &, const eversion_t &, PGTransaction *, const eversion_t &, const eversion_t &, const vector<pg_log_entry_t> &, Context *, Context *, Context *, ceph_tid_t, osd_reqid_t, OpRequestRef)
## ReplicatedPG.cc:7467		void ReplicatedPG::issue_repop(RepGather *)
## ReplicatedPG.cc:2364		void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750		void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296		void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438			void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332			void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.620564 7f6f4336f700 10 journal op_submit_finish 2665
##
## ReplicatedPG.cc:7280         void ReplicatedPG::eval_repop(RepGather *)
## ReplicatedPG.cc:2366		void ReplicatedPG::execute_ctx(OpContext *)
## ReplicatedPG.cc:1750		void ReplicatedPG::do_op(OpRequestRef &)
## ReplicatedPG.cc:1296		void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438			void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332			void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.620571 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 lua=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] eval_repop repgather(0x7f6f6575b3c0 30'1 rep_tid=1901 committed?=0 applied?=0 lock=0 op=osd_op(client.4141.0:1 t2.dat [writefull 0~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) wants=d
##
## OSD.cc:8441			void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332			void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.620582 7f6f4336f700 10 osd.0 30 dequeue_op 0x7f6f64d2bc00 finish
##
## FileJournal.cc:1167          void FileJournal::write_thread_entry()
## // kicked by FileJournal::submit_entry()
##
2015-11-23 08:48:50.620595 7f6f554e2700 20 journal write_thread_entry woke up
##
## FileJournal.cc:750           int FileJournal::check_for_full(uint64_t, off64_t, off64_t)
## FileJournal.cc:899           int FileJournal::prepare_single_write(bufferlist &, uint64_t &, uint64_t &)
## FileJournal.cc:793           int FileJournal::prepare_multi_write(bufferlist &, uint64_t &, uint64_t &)
## FileJournal.cc:1209          void FileJournal::write_thread_entry()
##
2015-11-23 08:48:50.620597 7f6f554e2700 10 journal room 5368696831 max_size 5368709120 pos 27791360 header.start 27783168 top 4096
##
## FileJournal.cc:762           int FileJournal::check_for_full(uint64_t, off64_t, off64_t)
## FileJournal.cc:899           int FileJournal::prepare_single_write(bufferlist &, uint64_t &, uint64_t &)
## FileJournal.cc:793           int FileJournal::prepare_multi_write(bufferlist &, uint64_t &, uint64_t &)
## FileJournal.cc:1209          void FileJournal::write_thread_entry()
##
2015-11-23 08:48:50.620598 7f6f554e2700 10 journal check_for_full at 27791360 : 4202496 < 5368696831
##
## FileJournal.cc:907           int FileJournal::prepare_single_write(bufferlist &, uint64_t &, uint64_t &)
## FileJournal.cc:793           int FileJournal::prepare_multi_write(bufferlist &, uint64_t &, uint64_t &)
## FileJournal.cc:1209          void FileJournal::write_thread_entry()
##
2015-11-23 08:48:50.620599 7f6f554e2700 15 journal prepare_single_write 1 will write 27791360 : seq 2665 len 4196455 -> 4202496 (head 40 pre_pad 4046 ebl 4196455 post_pad 1915 tail 40) (ebl alignment 4086)
##
## FileJournal.cc:832           int FileJournal::prepare_multi_write(bufferlist &, uint64_t &, uint64_t &)
## FileJournal.cc:1209          void FileJournal::write_thread_entry()
##
2015-11-23 08:48:50.622463 7f6f554e2700 20 journal prepare_multi_write queue_pos now 31993856
##
## FileJournal.cc:1272          void FileJournal::do_aio_write(bufferlist &)
## FileJournal.cc:1237          void FileJournal::write_thread_entry()
##
2015-11-23 08:48:50.622464 7f6f554e2700 15 journal do_aio_write writing 27791360~4202496
##
## FileJournal.cc:958           void FileJournal::align_bl(off64_t, bufferlist &)
## FileJournal.cc:1337          void FileJournal::write_aio_bl(off64_t &, bufferlist &, uint64_t)
## FileJournal.cc:1309          void FileJournal::do_aio_write(bufferlist &)
## FileJournal.cc:1237          void FileJournal::write_thread_entry()
##
2015-11-23 08:48:50.624590 7f6f554e2700 10 journal align_bl total memcopy: 4202496
##
## FileJournal.cc:1339          void FileJournal::write_aio_bl(off64_t &, bufferlist &, uint64_t)
## FileJournal.cc:1309          void FileJournal::do_aio_write(bufferlist &)
## FileJournal.cc:1237          void FileJournal::write_thread_entry()
##
2015-11-23 08:48:50.624600 7f6f554e2700 20 journal write_aio_bl 27791360~4202496 seq 2665
##
## FileJournal.cc:1364          void FileJournal::write_aio_bl(off64_t &, bufferlist &, uint64_t) // kicks write_finish thread, FileJournal.cc:1386
## FileJournal.cc:1309          void FileJournal::do_aio_write(bufferlist &)
## FileJournal.cc:1237          void FileJournal::write_thread_entry()
##
2015-11-23 08:48:50.624604 7f6f554e2700 20 journal write_aio_bl .. 27791360~4202496 in 1
##
## FileJournal.cc:1665          void FileJournal::put_throttle(uint64_t, uint64_t)
## FileJournal.cc:1237          void FileJournal::write_thread_entry()
##
2015-11-23 08:48:50.624908 7f6f554e2700  5 journal put_throttle finished 1 ops and 4196455 bytes, now 0 ops and 0 bytes
##
## FileJournal.cc:1165          void FileJournal::write_thread_entry()
##
2015-11-23 08:48:50.624912 7f6f554e2700 20 journal write_thread_entry going to sleep
##
## FileJournal.cc:1407          void FileJournal::write_finish_thread_entry() // kicked by FileJournal::write_aio_bl (FileJournal.cc:1364)
##
2015-11-23 08:48:50.624988 7f6f54ce1700 20 journal write_finish_thread_entry waiting for aio(s)
##
## FileStore.cc:3480            void FileStore::sync_entry() // woke up by a timer
## FileStore.h:173              void *FileStore::SyncThread::entry()
##
2015-11-23 08:48:50.682574 7f6f55ce3700 20 filestore(/var/lib/ceph/osd/ceph-0) sync_entry woke after 5.000104
##
## JournalingObjectStore.cc:193 void JournalingObjectStore::ApplyManager::commit_start()
## FileStore.cc:3496            void FileStore::sync_entry()
## FileStore.h:173              void *FileStore::SyncThread::entry()
##
2015-11-23 08:48:50.682600 7f6f55ce3700 10 journal commit_start max_applied_seq 2664, open_ops 0
##
## JournalingObjectStore.cc:202 void JournalingObjectStore::ApplyManager::commit_start()
## FileStore.cc:3496            void FileStore::sync_entry()
## FileStore.h:173              void *FileStore::SyncThread::entry()
##
2015-11-23 08:48:50.682602 7f6f55ce3700 10 journal commit_start blocked, all open_ops have completed
##
## JournalingObjectStore.cc:214 void JournalingObjectStore::ApplyManager::commit_start()
## FileStore.cc:3496            void FileStore::sync_entry()
## FileStore.h:173              void *FileStore::SyncThread::entry()
##
2015-11-23 08:48:50.682603 7f6f55ce3700 10 journal commit_start committing 2664, still blocked
##
## FileJournal.cc:1544          void FileJournal::commit_start(uint64_t)
## JournalingObjectStore.cc:222 void JournalingObjectStore::ApplyManager::commit_start()
## FileStore.cc:3496            void FileStore::sync_entry()
## FileStore.h:173              void *FileStore::SyncThread::entry()
##
2015-11-23 08:48:50.682605 7f6f55ce3700 10 journal commit_start
##
## FileStore.cc:3508            void FileStore::sync_entry()
## FileStore.h:173              void *FileStore::SyncThread::entry()
##
2015-11-23 08:48:50.682609 7f6f55ce3700 15 filestore(/var/lib/ceph/osd/ceph-0) sync_entry committing 2664
##
## JournalingObjectStore.cc:230 void JournalingObjectStore::ApplyManager::commit_started()
## FileStore.cc:3547            void FileStore::sync_entry()
## FileStore.h:173              void *FileStore::SyncThread::entry()
##
2015-11-23 08:48:50.682612 7f6f55ce3700 10 journal commit_started committing 2664, unblocking
##
## GenericFileStoreBackend.cc:204 int GenericFileStoreBackend::syncfs() // SyncThread blocks on syncfs()
## FileStore.cc:3550              void FileStore::sync_entry()
## FileStore.h:173                void *FileStore::SyncThread::entry()
##
2015-11-23 08:48:50.682615 7f6f55ce3700 15 genericfilestorebackend(/var/lib/ceph/osd/ceph-0) syncfs: doing a full sync (syncfs(2) if possible)
##
## OSD.cc:671                     void OSD::update_osd_stat(vector<int> &)
## OSD.cc:3819                    void OSD::heartbeat()
##
2015-11-23 08:48:50.721336 7f6f3f367700 20 osd.0 30 update_osd_stat osd_stat(37592 kB used, 255 GB avail, 255 GB total, peers [1,2]/[] op hist [0,0,0,0,0,0,0,1])
##
## OSD.cc:3821                    void OSD::heartbeat()
##
2015-11-23 08:48:50.721353 7f6f3f367700  5 osd.0 30 heartbeat: osd_stat(37592 kB used, 255 GB avail, 255 GB total, peers [1,2]/[] op hist [0,0,0,0,0,0,0,1])
2015-11-23 08:48:50.721902 7f6f4cb82700 20 osd.0 30 share_map_peer 0x7f6f64eb9440 already has epoch 30
2015-11-23 08:48:50.721912 7f6f4cb82700 20 osd.0 30 share_map_peer 0x7f6f64eb9440 already has epoch 30
2015-11-23 08:48:50.722179 7f6f4cb82700 20 osd.0 30 share_map_peer 0x7f6f65173080 already has epoch 30
2015-11-23 08:48:50.722187 7f6f4cb82700 20 osd.0 30 share_map_peer 0x7f6f65173080 already has epoch 30
##
## FileJournal.cc:1428           void FileJournal::write_finish_entry() // unblocked from io_getevents
##
2015-11-23 08:48:50.793402 7f6f54ce1700 10 journal write_finish_thread_entry aio 27791360~4202496 done
##
## FileJournal.cc:1446           void FileJournal::check_aio_completion()
## FileJournal.cc:1432           void FileJournal::write_finish_entry() // unblocked from io_getevents
##
2015-11-23 08:48:50.793429 7f6f54ce1700 20 journal check_aio_completion
##
## FileJournal.cc:1453           void FileJournal::check_aio_completion()
## FileJournal.cc:1432           void FileJournal::write_finish_entry() // unblocked from io_getevents
##
2015-11-23 08:48:50.793431 7f6f54ce1700 20 journal check_aio_completion completed seq 2665 27791360~4202496
##
## FileJournal.cc:1478           void FileJournal::check_aio_completion()
## FileJournal.cc:1432           void FileJournal::write_finish_entry() // unblocked from io_getevents
##
2015-11-23 08:48:50.793437 7f6f54ce1700 20 journal check_aio_completion queueing finishers through seq 2665
##
## FileJournal.cc:868            void FileJournal::queue_completions_thru(uint64_t) // kicks finisher
## FileJournal.cc:1479           void FileJournal::check_aio_completion()
## FileJournal.cc:1432           void FileJournal::write_finish_entry() // unblocked from io_getevents
##
2015-11-23 08:48:50.793439 7f6f54ce1700 10 journal queue_completions_thru seq 2665 queueing seq 2665 0x7f6f66cb5450 lat 0.172885
##
## FileJournal.cc:1401           void FileJournal::write_finish_entry()
##
2015-11-23 08:48:50.793463 7f6f54ce1700 20 journal write_finish_thread_entry sleeping
##
## FileStore.cc:1967             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *)
## // callback invoked by finisher thread, set at FileStore::queue_transactions() (FileStore.cc:1907)
## // Op holds the following callbacks:
## // onreadable_sync: C_OSD_OndiskWriteLock::finish(int)
## // onreadable:      ReplicatedBackend::op_applied(InProgressOp *) <- ReplicatedPG::repop_all_applied(RepGather *)

##
2015-11-23 08:48:50.793567 7f6f544e0700  5 filestore(/var/lib/ceph/osd/ceph-0) _journaled_ahead 0x7f6f64f854f0 seq 2665 osr(1.2d 0x7f6f64cfdee0) 0x7f6f657e0d80
##
## FileStore.cc:1725             void FileStore::queue_op(OpSequencer *, Op *)
## FileStore.cc:1970             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *)
## // callback invoked by finisher thread, set at FileStore::queue_transactions() (FileStore.cc:1907)
##
2015-11-23 08:48:50.793576 7f6f544e0700  5 filestore(/var/lib/ceph/osd/ceph-0) queue_op 0x7f6f64f854f0 seq 2665 osr(1.2d 0x7f6f64cfdee0) 4196441 bytes   (queue has 1 ops and 4196441 bytes)
##
## FileStore.cc:1978             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *)
## // callback invoked by finisher thread, set at FileStore::queue_transactions() (FileStore.cc:1907)
##
2015-11-23 08:48:50.793581 7f6f544e0700 10 filestore(/var/lib/ceph/osd/ceph-0)  queueing ondisk 0x7f6f669e47a0
##
## JournalingObjectStore.cc:127     uint64_t JournalingObjectStore::ApplyManager::op_apply_start(uint64_t)
## FileStore.cc:1800                void FileStore::_do_op(OpSequencer *, ThreadPool::TPHandle &)
## FileStore.h:359                  void FileStore::OpWq::_process(OpSequencer *, ThreadPool::TPHandle &)
## // FileStore.cc:1730             void FileStore::queue_op(OpSequencer *, Op *)
## // FileStore.cc:1970             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *)
## // callback invoked by finisher thread, set at FileStore::queue_transactions() (FileStore.cc:1907)
##
2015-11-23 08:48:50.793597 7f6f534de700 10 journal op_apply_start 2665 open_ops 0 -> 1
##
## FileStore.cc:1801                void FileStore::_do_op(OpSequencer *, ThreadPool::TPHandle &)
## FileStore.h:359                  void FileStore::OpWq::_process(OpSequencer *, ThreadPool::TPHandle &)
## // FileStore.cc:1730             void FileStore::queue_op(OpSequencer *, Op *)
## // FileStore.cc:1970             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *)
## // callback invoked by finisher thread, set at FileStore::queue_transactions() (FileStore.cc:1907)
##
2015-11-23 08:48:50.793599 7f6f534de700  5 filestore(/var/lib/ceph/osd/ceph-0) _do_op 0x7f6f64f854f0 seq 2665 osr(1.2d 0x7f6f64cfdee0)/0x7f6f64cfdee0 start
##
## // XXX: FileStore::_do_transaction() either assert()'s, or returns 0
## FileStore.cc:2267                unsigned FileStore::_do_transaction(Transaction &, uint64_t, int, ThreadPool::TPHandle *)
## FileStore.cc:1997                int  FileStore::_do_transactions(list<Transaction *> &, uint64_t, ThreadPool::TPHandle *)
## // XXX: FileStore::_do_op() ignores the error code returned by FileStore::_do_transactions()
## FileStore.cc:1802                void FileStore::_do_op(OpSequencer *, ThreadPool::TPHandle &)
## FileStore.h:359                  void FileStore::OpWq::_process(OpSequencer *, ThreadPool::TPHandle &)
## // FileStore.cc:1730             void FileStore::queue_op(OpSequencer *, Op *)
## // FileStore.cc:1970             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *)
## // callback invoked by finisher thread, set at FileStore::queue_transactions() (FileStore.cc:1907)
##
2015-11-23 08:48:50.793601 7f6f534de700 10 filestore(/var/lib/ceph/osd/ceph-0) _do_transaction on 0x7f6f657e0d80
##
## FileStore.cc:4999                int  FileStore::_omap_setkeys(coll_t, const ghobject_t &, const map<string, bufferlist> &, const SequencerPosition &)
## FileStore.cc:2601                unsigned FileStore::_do_transaction(Transaction &, uint64_t, int, ThreadPool::TPHandle *)
## FileStore.cc:1997                int  FileStore::_do_transactions(list<Transaction *> &, uint64_t, ThreadPool::TPHandle *)
## FileStore.cc:1802                void FileStore::_do_op(OpSequencer *, ThreadPool::TPHandle &)
## FileStore.h:359                  void FileStore::OpWq::_process(OpSequencer *, ThreadPool::TPHandle &)
## // FileStore.cc:1730             void FileStore::queue_op(OpSequencer *, Op *)
## // FileStore.cc:1970             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *)
## // callback invoked by finisher thread, set at FileStore::queue_transactions() (FileStore.cc:1907)
##
2015-11-23 08:48:50.793612 7f6f534de700 15 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1
##
## ReplicatedBackend.cc:659         void ReplicatedBackend::op_commit(InProgressOp *)
## // callback set by
## // ReplicatedBackend.cc:632 void ReplicatedBackend::submit_transaction(const hobject_t &, const eversion_t &, PGTransaction *, const eversion_t &, const eversion_t &, const vector<pg_log_entry_t> &, Context *, Context *, Context *, ceph_tid_t, osd_reqid_t, OpRequestRef)
## // XXX: which thread is this?
##
2015-11-23 08:48:50.793611 7f6f524dc700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 lua=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] op_commit: 1901
##
## DBObjectMap.cc:1233              bool DBObjectMap::check_spos(const ghobject_t &, Header, const SequencerPosition *)
## DBObjectMap.cc:450               int  DBObjectMap::set_keys(const ghobject_t &, const map<string, bufferlist> &, const SequencerPosition *)
## FileStore.cc:5015                int  FileStore::_omap_setkeys(coll_t, const ghobject_t &, const map<string, bufferlist> &, const SequencerPosition &)
## FileStore.cc:2601                unsigned FileStore::_do_transaction(Transaction &, uint64_t, int, ThreadPool::TPHandle *)
## FileStore.cc:1997                int  FileStore::_do_transactions(list<Transaction *> &, uint64_t, ThreadPool::TPHandle *)
## FileStore.cc:1802                void FileStore::_do_op(OpSequencer *, ThreadPool::TPHandle &)
## FileStore.h:359                  void FileStore::OpWq::_process(OpSequencer *, ThreadPool::TPHandle &)
## // FileStore.cc:1730             void FileStore::queue_op(OpSequencer *, Op *)
## // FileStore.cc:1970             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *)
## // callback invoked by finisher thread, set at FileStore::queue_transactions() (FileStore.cc:1907)
##
2015-11-23 08:48:50.793648 7f6f534de700 10 filestore oid: 2d//head//1 not skipping op, *spos 2665.0.0
##
## DBObjectMap.cc:1238              bool DBObjectMap::check_spos(const ghobject_t &, Header, const SequencerPosition *)
## DBObjectMap.cc:450               int  DBObjectMap::set_keys(const ghobject_t &, const map<string, bufferlist> &, const SequencerPosition *)
## FileStore.cc:5015                int  FileStore::_omap_setkeys(coll_t, const ghobject_t &, const map<string, bufferlist> &, const SequencerPosition &)
## FileStore.cc:2601                unsigned FileStore::_do_transaction(Transaction &, uint64_t, int, ThreadPool::TPHandle *)
## FileStore.cc:1997                int  FileStore::_do_transactions(list<Transaction *> &, uint64_t, ThreadPool::TPHandle *)
## FileStore.cc:1802                void FileStore::_do_op(OpSequencer *, ThreadPool::TPHandle &)
## FileStore.h:359                  void FileStore::OpWq::_process(OpSequencer *, ThreadPool::TPHandle &)
## // FileStore.cc:1730             void FileStore::queue_op(OpSequencer *, Op *)
## // FileStore.cc:1970             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *)
## // callback invoked by finisher thread, set at FileStore::queue_transactions() (FileStore.cc:1907)
##
2015-11-23 08:48:50.793649 7f6f534de700 10 filestore  > header.spos 0.0.0
##
## FileStore.cc:5016                int  FileStore::_omap_setkeys(coll_t, const ghobject_t &, const map<string, bufferlist> &, const SequencerPosition &)
## FileStore.cc:2601                unsigned FileStore::_do_transaction(Transaction &, uint64_t, int, ThreadPool::TPHandle *)
## FileStore.cc:1997                int  FileStore::_do_transactions(list<Transaction *> &, uint64_t, ThreadPool::TPHandle *)
## FileStore.cc:1802                void FileStore::_do_op(OpSequencer *, ThreadPool::TPHandle &)
## FileStore.h:359                  void FileStore::OpWq::_process(OpSequencer *, ThreadPool::TPHandle &)
## // FileStore.cc:1730             void FileStore::queue_op(OpSequencer *, Op *)
## // FileStore.cc:1970             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *)
## // callback invoked by finisher thread, set at FileStore::queue_transactions() (FileStore.cc:1907)
##
2015-11-23 08:48:50.793822 7f6f534de700 20 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1 = 0
2015-11-23 08:48:50.793838 7f6f534de700 15 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1
2015-11-23 08:48:50.793850 7f6f534de700 10 filestore oid: 2d//head//1 not skipping op, *spos 2665.0.1
2015-11-23 08:48:50.793851 7f6f534de700 10 filestore  > header.spos 0.0.0
2015-11-23 08:48:50.793907 7f6f534de700 20 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1 = 0
2015-11-23 08:48:50.793922 7f6f534de700 15 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1
2015-11-23 08:48:50.793933 7f6f534de700 10 filestore oid: 2d//head//1 not skipping op, *spos 2665.0.2
2015-11-23 08:48:50.793934 7f6f534de700 10 filestore  > header.spos 0.0.0
2015-11-23 08:48:50.793975 7f6f534de700 20 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1 = 0
##
## FileStore.cc:3006                int  FileStore::_write(coll_t, const ghobject_t &, uint64_t, size_t, const bufferlist &, uint32_t)
## FileStore.cc:2310                unsigned FileStore::_do_transaction(Transaction &, uint64_t, int, ThreadPool::TPHandle *)
## FileStore.cc:1997                int  FileStore::_do_transactions(list<Transaction *> &, uint64_t, ThreadPool::TPHandle *)
## FileStore.cc:1802                void FileStore::_do_op(OpSequencer *, ThreadPool::TPHandle &)
## FileStore.h:359                  void FileStore::OpWq::_process(OpSequencer *, ThreadPool::TPHandle &)
## // FileStore.cc:1730             void FileStore::queue_op(OpSequencer *, Op *)
## // FileStore.cc:1970             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *)
## // callback invoked by finisher thread, set at FileStore::queue_transactions() (FileStore.cc:1907)
##
2015-11-23 08:48:50.793988 7f6f534de700 15 filestore(/var/lib/ceph/osd/ceph-0) write 1.2d_head/a3002fad/t2.dat/head//1 0~4194304
##
## FileStore.cc:3053                int  FileStore::_write(coll_t, const ghobject_t &, uint64_t, size_t, const bufferlist &, uint32_t)
## FileStore.cc:2310                unsigned FileStore::_do_transaction(Transaction &, uint64_t, int, ThreadPool::TPHandle *)
## FileStore.cc:1997                int  FileStore::_do_transactions(list<Transaction *> &, uint64_t, ThreadPool::TPHandle *)
## FileStore.cc:1802                void FileStore::_do_op(OpSequencer *, ThreadPool::TPHandle &)
## FileStore.h:359                  void FileStore::OpWq::_process(OpSequencer *, ThreadPool::TPHandle &)
## // FileStore.cc:1730             void FileStore::queue_op(OpSequencer *, Op *)
## // FileStore.cc:1970             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *)
## // callback invoked by finisher thread, set at FileStore::queue_transactions() (FileStore.cc:1907)
##
2015-11-23 08:48:50.795918 7f6f534de700 10 filestore(/var/lib/ceph/osd/ceph-0) write 1.2d_head/a3002fad/t2.dat/head//1 0~4194304 = 4194304
2015-11-23 08:48:50.796001 7f6f534de700 15 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1
2015-11-23 08:48:50.796023 7f6f534de700 10 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1 = 0
2015-11-23 08:48:50.796033 7f6f534de700 20 filestore(/var/lib/ceph/osd/ceph-0) fgetattrs 145 getting '_'
2015-11-23 08:48:50.796037 7f6f534de700 15 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1
2015-11-23 08:48:50.796042 7f6f534de700 10 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1 = 0
##
## JournalingObjectStore.cc:137     void JournalingObjectStore::ApplyManager::op_apply_finish(uint64_t)
## FileStore.cc:1803                void FileStore::_do_op(OpSequencer *, ThreadPool::TPHandle &)
## FileStore.h:359                  void FileStore::OpWQ::_process(OpSequencer *, ThreadPool::TPHandle &)
## WorkQueue.h:256                  void WorkQueue<T>::_void_process(void *, TPHandle &)
## WorkQueue.cc:128                 void ThreadPool::worker(WorkThread *)
## // FileStore.cc:1730             void FileStore::queue_op(OpSequencer *, Op *)
## // FileStore.cc:1970             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *)
## // callback invoked by finisher thread, set at FileStore::queue_transactions() (FileStore.cc:1907)
##
2015-11-23 08:48:50.796046 7f6f534de700 10 journal op_apply_finish 2665 open_ops 1 -> 0, max_applied_seq 2664 -> 2665
##
## FileStore.cc:1804                void FileStore::_do_op(OpSequencer *, ThreadPool::TPHandle &)
## FileStore.h:359                  void FileStore::OpWq::_process(OpSequencer *, ThreadPool::TPHandle &)
## WorkQueue.h:256                  void WorkQueue<T>::_void_process(void *, TPHandle &)
## WorkQueue.cc:128                 void ThreadPool::worker(WorkThread *)
## // FileStore.cc:1730             void FileStore::queue_op(OpSequencer *, Op *)
## // FileStore.cc:1970             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *)
## // callback invoked by finisher thread, set at FileStore::queue_transactions() (FileStore.cc:1907)
##
2015-11-23 08:48:50.796047 7f6f534de700 10 filestore(/var/lib/ceph/osd/ceph-0) _do_op 0x7f6f64f854f0 seq 2665 r = 0, finisher 0x7f6f669e2b80 0x7f6f669cea00
##
## // XXX: no error code passed to callbacks
## FileStore.cc:1813                void FileStore::_finish_op(OpSequencer *)
## //
## // queues onreadable callback in a different thread
## // onreadable <- on_applied <- ReplicatedBackend::op_applied(InProgressOp *) <- ReplicatedPG::repop_all_applied(RepGather *)
## //
## FileStore.h:362                  void FileStore::OpWq::_process_finish(OpSequencer *)
## WorkQueue.h:259                  void WorkQueue<T>::_void_process_finish(void *, TPHandle &)
## WorkQueue.cc:130                 void ThreadPool::worker(WorkThread *)
## // FileStore.cc:1730             void FileStore::queue_op(OpSequencer *, Op *)
## // FileStore.cc:1970             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *) // onjournal callback
## // Finisher.cc:59                void Finisher::finisher_thread_entry()
## // FileJournal.cc:880            void FileJournal::queue_completions_thru(uint64_t)
## // FileJournal.cc:1479           void FileJournal::check_aio_completion()
## // FileJournal.cc:1432           void FileJournal::write_finish_thread_entry()
## // FileJournal.cc:1373           int FileJournal::write_aio_bl(off64_t &, bufferlist &, uint64_t)
## // FileJournal.cc:1315           void FileJournal::do_aio_write(bufferlist &)
## // FileJournal.cc:1166           void FileJournal::write_thread_entry()
## // FileJournal.cc:1373           int FileJournal::submit_entry(uint64_t, bufferlist &, int, Context *, TrackedOpRef)
## // JournalingObjectStore.cc:273  void JournalingObjectStore::_op_journal_transactions(list<ObjectStore::Transaction *>, uint64_t, Context *, TrackedOpRef)
## // FileStore.cc:1980             int FileStore::queue_transactions(Sequencer *, list<Transaction *> &, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
##
2015-11-23 08:48:50.796050 7f6f534de700 10 filestore(/var/lib/ceph/osd/ceph-0) _finish_op 0x7f6f64f854f0 seq 2665 osr(1.2d 0x7f6f64cfdee0)/0x7f6f64cfdee0
##
## ReplicatedPG.cc:639              void ReplicatedBackend::op_applied(InProgressOp *)
## Finisher.cc:59                   void *Finisher::finisher_thread_entry()
##
## // FileStore.cc:1827             void FileStore::_finish_op(OpSequencer *)
## // FileStore.h:362               void FileStore::OpWq::_process_finish(OpSequencer *)
## // WorkQueue.h:259               void WorkQueue<T>::_void_process_finish(void *, TPHandle &)
## // WorkQueue.cc:130              void ThreadPool::worker(WorkThread *)
## // FileStore.cc:1730             void FileStore::queue_op(OpSequencer *, Op *)
## // FileStore.cc:1970             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *) // onjournal callback
## // Finisher.cc:59                void Finisher::finisher_thread_entry()
## // FileJournal.cc:880            void FileJournal::queue_completions_thru(uint64_t)
## // FileJournal.cc:1479           void FileJournal::check_aio_completion()
## // FileJournal.cc:1432           void FileJournal::write_finish_thread_entry()
## // FileJournal.cc:1373           int FileJournal::write_aio_bl(off64_t &, bufferlist &, uint64_t)
## // FileJournal.cc:1315           void FileJournal::do_aio_write(bufferlist &)
## // FileJournal.cc:1166           void FileJournal::write_thread_entry()
## // FileJournal.cc:1373           int FileJournal::submit_entry(uint64_t, bufferlist &, int, Context *, TrackedOpRef)
## // JournalingObjectStore.cc:273  void JournalingObjectStore::_op_journal_transactions(list<ObjectStore::Transaction *>, uint64_t, Context *, TrackedOpRef)
## // FileStore.cc:1980             int FileStore::queue_transactions(Sequencer *, list<Transaction *> &, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
##
2015-11-23 08:48:50.796188 7f6f52cdd700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 lua=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] op_applied: 1901
##
## ReplicatedPG.cc:7249             void ReplicatedPG::op_applied(const eversion_t &)
## ReplicatedBackend.cc:639         void ReplicatedBackend::op_applied(InProgressOp *)
## Finisher.cc:59                   void *Finisher::finisher_thread_entry()
##
## // FileStore.cc:1827             void FileStore::_finish_op(OpSequencer *)
## // FileStore.h:362               void FileStore::OpWq::_process_finish(OpSequencer *)
## // WorkQueue.h:259               void WorkQueue<T>::_void_process_finish(void *, TPHandle &)
## // WorkQueue.cc:130              void ThreadPool::worker(WorkThread *)
## // FileStore.cc:1730             void FileStore::queue_op(OpSequencer *, Op *)
## // FileStore.cc:1970             void FileStore::_journaled_ahead(OpSequencer *, Op *, Context *) // onjournal callback
## // Finisher.cc:59                void Finisher::finisher_thread_entry()
## // FileJournal.cc:880            void FileJournal::queue_completions_thru(uint64_t)
## // FileJournal.cc:1479           void FileJournal::check_aio_completion()
## // FileJournal.cc:1432           void FileJournal::write_finish_thread_entry()
## // FileJournal.cc:1373           int FileJournal::write_aio_bl(off64_t &, bufferlist &, uint64_t)
## // FileJournal.cc:1315           void FileJournal::do_aio_write(bufferlist &)
## // FileJournal.cc:1166           void FileJournal::write_thread_entry()
## // FileJournal.cc:1373           int FileJournal::submit_entry(uint64_t, bufferlist &, int, Context *, TrackedOpRef)
## // JournalingObjectStore.cc:273  void JournalingObjectStore::_op_journal_transactions(list<ObjectStore::Transaction *>, uint64_t, Context *, TrackedOpRef)
## // FileStore.cc:1980             int FileStore::queue_transactions(Sequencer *, list<Transaction *> &, Context *, Context *, Context *, TrackedOpRef, ThreadPool::TPHandle *)
##
2015-11-23 08:48:50.796216 7f6f52cdd700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 lua=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] op_applied version 30'1
##
#### OSD #2 reports the operation has been committed
##
## OSD.cc:8209                      void OSD::handle_replica_op<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef &, OSDMapRef &)
## OSD.cc:5740                      bool OSD::dispatch_op_fast(OpRequestRef &, OSDMapRef &)
## OSD.cc:5374                      void OSD::dispatch_session_waiting(Session *, OSDMapRef)
##
2015-11-23 08:48:50.813447 7f6f3aa4f700 10 osd.0 30 handle_replica_op osd_repop_reply(client.4141.0:1 1.2d ondisk, result = 0) v1 epoch 30
##
## OSD.cc:799                       bool OSDService::should_share_map(entity_name_t, Connection *, epoch_t, OSDRefMap&, const epoch_t *)
## OSD.cc:8228                      void OSD::handle_replica_op<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef &, OSDMapRef &)
## OSD.cc:5740                      bool OSD::dispatch_op_fast(OpRequestRef &, OSDMapRef &)
## OSD.cc:5374                      void OSD::dispatch_session_waiting(Session *, OSDMapRef)
##
2015-11-23 08:48:50.813467 7f6f3aa4f700 20 osd.0 30 should_share_map osd.2 10.253.0.5:6801/3128 30
##
## OSD.cc:8262                      void OSD::enqueue_op(PG *, OpRequestRef &)
## OSD.cc:8241                      void OSD::handle_replica_op<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef &, OSDMapRef &)
## OSD.cc:5740                      bool OSD::dispatch_op_fast(OpRequestRef &, OSDMapRef &)
## OSD.cc:5374                      void OSD::dispatch_session_waiting(Session *, OSDMapRef)
##
2015-11-23 08:48:50.813472 7f6f3aa4f700 15 osd.0 30 enqueue_op 0x7f6f64d2de00 prio 196 cost 0 latency 0.000115 osd_repop_reply(client.4141.0:1 1.2d ondisk, result = 0) v1
##
## OSD.cc:8408                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
## // OSD.cc:8262                  void OSD::enqueue_op(PG *, OpRequestRef &)
## // OSD.cc:8241                  void OSD::handle_replica_op<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef &, OSDMapRef &)
## // OSD.cc:5740                  bool OSD::dispatch_op_fast(OpRequestRef &, OSDMapRef &)
## // OSD.cc:5374                  void OSD::dispatch_session_waiting(Session *, OSDMapRef)
##
2015-11-23 08:48:50.813492 7f6f45b74700 10 osd.0 30 dequeue_op 0x7f6f64d2de00 prio 196 cost 0 latency 0.000135 osd_repop_reply(client.4141.0:1 1.2d ondisk, result = 0) v1 pg pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean]
##
## ReplicatedBackend.cc:162        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.813506 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] handle_message: 0x7f6f64d2de00
##
## // Note: ack_type 4 == CEPH_OSD_FLAG_ONDISK
## ReplicatedBackend.cc:698        void ReplicatedBackend::sub_op_modify_reply<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef)
## ReplicatedBackend.cc:221        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.813515 7f6f45b74700  7 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] sub_op_modify_reply: tid 1901 op  ack_type 4 from 2
##
## // End of "OSD #2 reports the operation has been committed"
## OSD.cc:8441                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.813529 7f6f45b74700 10 osd.0 30 dequeue_op 0x7f6f64d2de00 finish
##
#### OSD #1 reports the operation has been committed
##
## OSD.cc:8209                      void OSD::handle_replica_op<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef &, OSDMapRef &)
## OSD.cc:5740                      bool OSD::dispatch_op_fast(OpRequestRef &, OSDMapRef &)
## OSD.cc:5374                      void OSD::dispatch_session_waiting(Session *, OSDMapRef)
##
2015-11-23 08:48:50.882665 7f6f3b85d700 10 osd.0 30 handle_replica_op osd_repop_reply(client.4141.0:1 1.2d ondisk, result = 0) v1 epoch 30
##
## OSD.cc:799                       bool OSDService::should_share_map(entity_name_t, Connection *, epoch_t, OSDRefMap&, const epoch_t *)
## OSD.cc:8228                      void OSD::handle_replica_op<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef &, OSDMapRef &)
## OSD.cc:5740                      bool OSD::dispatch_op_fast(OpRequestRef &, OSDMapRef &)
## OSD.cc:5374                      void OSD::dispatch_session_waiting(Session *, OSDMapRef)
##
2015-11-23 08:48:50.882669 7f6f3b85d700 20 osd.0 30 should_share_map osd.1 10.253.0.4:6801/3119 30
##
## OSD.cc:8262                      void OSD::enqueue_op(PG *, OpRequestRef &)
## OSD.cc:8241                      void OSD::handle_replica_op<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef &, OSDMapRef &)
## OSD.cc:5740                      bool OSD::dispatch_op_fast(OpRequestRef &, OSDMapRef &)
## OSD.cc:5374                      void OSD::dispatch_session_waiting(Session *, OSDMapRef)
##
2015-11-23 08:48:50.882673 7f6f3b85d700 15 osd.0 30 enqueue_op 0x7f6f64d2dd00 prio 196 cost 0 latency 0.000115 osd_repop_reply(client.4141.0:1 1.2d ondisk, result = 0) v1
##
## OSD.cc:8408          void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332          void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.882845 7f6f4336f700 10 osd.0 30 dequeue_op 0x7f6f64d2dd00 prio 196 cost 0 latency 0.000287 osd_repop_reply(client.4141.0:1 1.2d ondisk, result = 0) v1 pg pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean]
##
## ReplicatedBackend.cc:162        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.882863 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] handle_message: 0x7f6f64d2dd00
##
## // Note: ack_type 4 == CEPH_OSD_FLAG_ONDISK
## ReplicatedBackend.cc:698        void ReplicatedBackend::sub_op_modify_reply<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef)
## ReplicatedBackend.cc:221        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.882871 7f6f4336f700  7 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] sub_op_modify_reply: tid 1901 op  ack_type 4 from 1
##
## ReplicatedPG.cc:7209            void ReplicatedPG::repop_all_applied(RepGather *)
## // in_op->on_applied = ReplicatedPG::repop_all_applied(RepGather *)
## // invoked via InProgressOp->on_applied->complete(0)
## ReplicatedBackend.cc:727        void ReplicatedBackend::sub_op_modify_reply<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef)
## ReplicatedBackend.cc:221        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.882896 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] repop_all_applied: repop tid 1901 all applied 
##
## ReplicatedPG.cc:7234            void ReplicatedPG::repop_all_committed(RepGather *)
## // in_op->on_commit = ReplicatedPG::repop_all_committed(RepGather *)
## // invoked via InProgressOp->on_commit->complete(0)
## ReplicatedBackend.cc:732        void ReplicatedBackend::sub_op_modify_reply<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef)
## ReplicatedBackend.cc:221        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.882901 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] eval_repop repgather(0x7f6f6575b3c0 30'1 rep_tid=1901 committed?=0 applied?=1 lock=0 op=osd_op(client.4141.0:1 t2.dat [writefull 0~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) wants=d
##
## ReplicatedPG.cc:7234            void ReplicatedPG::repop_all_committed(RepGather *)
## // in_op->on_commit = ReplicatedPG::repop_all_committed(RepGather *)
## // invoked via InProgressOp->on_commit->complete(0)
## ReplicatedBackend.cc:732        void ReplicatedBackend::sub_op_modify_reply<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef)
## ReplicatedBackend.cc:221        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.882911 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=0'0 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] repop_all_committed: repop tid 1901 all committed 
##
## ReplicatedPG.cc:7280            void ReplicatedPG::eval_repop(RepGather *)
## ReplicatedPG.cc:7243            void ReplicatedPG::repop_all_committed(RepGather *)
## // in_op->on_commit = ReplicatedPG::repop_all_committed(RepGather *)
## // invoked via InProgressOp->on_commit->complete(0)
## ReplicatedBackend.cc:732        void ReplicatedBackend::sub_op_modify_reply<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef)
## ReplicatedBackend.cc:221        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.882914 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] eval_repop repgather(0x7f6f6575b3c0 30'1 rep_tid=1901 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:1 t2.dat [writefull 0~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) wants=d
##
## ReplicatedPG.cc:2434            void ReplicatedPG::log_op_stats(OpContext *)
## ReplicatedPG.cc:7295            void ReplicatedPG::eval_repop(RepGather *)
## ReplicatedPG.cc:7243            void ReplicatedPG::repop_all_committed(RepGather *)
## // in_op->on_commit = ReplicatedPG::repop_all_committed(RepGather *)
## // invoked via InProgressOp->on_commit->complete(0)
## ReplicatedBackend.cc:732        void ReplicatedBackend::sub_op_modify_reply<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef)
## ReplicatedBackend.cc:221        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.882920 7f6f4336f700 15 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] log_op_stats osd_op(client.4141.0:1 t2.dat [writefull 0~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5 inb 4194304 outb 0 rlat 0.276591 lat 0.276603
## 
## PG.cc:2467                      void PG::publish_stats_to_osd()
## ReplicatedPG.cc:7298            void ReplicatedPG::eval_repop(RepGather *)
## ReplicatedPG.cc:7243            void ReplicatedPG::repop_all_committed(RepGather *)
## // in_op->on_commit = ReplicatedPG::repop_all_committed(RepGather *)
## // invoked via InProgressOp->on_commit->complete(0)
## ReplicatedBackend.cc:732        void ReplicatedBackend::sub_op_modify_reply<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef)
## ReplicatedBackend.cc:221        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.882928 7f6f4336f700 15 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] publish_stats_to_osd 30:13
##
## ReplicatedPG.cc:7330            void ReplicatedPG::eval_repop(RepGather *)
## ReplicatedPG.cc:7243            void ReplicatedPG::repop_all_committed(RepGather *)
## // in_op->on_commit = ReplicatedPG::repop_all_committed(RepGather *)
## // invoked via InProgressOp->on_commit->complete(0)
## ReplicatedBackend.cc:732        void ReplicatedBackend::sub_op_modify_reply<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef)
## ReplicatedBackend.cc:221        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.882931 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean]  sending commit on repgather(0x7f6f6575b3c0 30'1 rep_tid=1901 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:1 t2.dat [writefull 0~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) 0x7f6f65726100
##
## ReplicatedPG.cc:5517            void ReplicatedPG::do_osd_op_effects(OpContext *, const ConnectionRef &)
## ReplicatedPG.cc:7386            void ReplicatedPG::eval_repop(RepGather *)
## ReplicatedPG.cc:7243            void ReplicatedPG::repop_all_committed(RepGather *)
## // in_op->on_commit = ReplicatedPG::repop_all_committed(RepGather *)
## // invoked via InProgressOp->on_commit->complete(0)
## ReplicatedBackend.cc:732        void ReplicatedBackend::sub_op_modify_reply<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef)
## ReplicatedBackend.cc:221        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.882951 7f6f4336f700 15 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] do_osd_op_effects client.4141 con 0x7f6f66884680
##
## ReplicatedPG.cc:7398            void ReplicatedPG::eval_repop(RepGather *)
## ReplicatedPG.cc:7243            void ReplicatedPG::repop_all_committed(RepGather *)
## // in_op->on_commit = ReplicatedPG::repop_all_committed(RepGather *)
## // invoked via InProgressOp->on_commit->complete(0)
## ReplicatedBackend.cc:732        void ReplicatedBackend::sub_op_modify_reply<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef)
## ReplicatedBackend.cc:221        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.882958 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean]  removing repgather(0x7f6f6575b3c0 30'1 rep_tid=1901 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:1 t2.dat [writefull 0~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5)
##
## ReplicatedPG.cc:7400            void ReplicatedPG::eval_repop(RepGather *)
## ReplicatedPG.cc:7243            void ReplicatedPG::repop_all_committed(RepGather *)
## // in_op->on_commit = ReplicatedPG::repop_all_committed(RepGather *)
## // invoked via InProgressOp->on_commit->complete(0)
## ReplicatedBackend.cc:732        void ReplicatedBackend::sub_op_modify_reply<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef)
## ReplicatedBackend.cc:221        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.882963 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean]    q front is repgather(0x7f6f6575b3c0 30'1 rep_tid=1901 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:1 t2.dat [writefull 0~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5)
##
## ReplicatedPG.cc:7507            void ReplicatedPG::remove_repop(RepGather *)
## ReplicatedPG.cc:7407            void ReplicatedPG::eval_repop(RepGather *)
## ReplicatedPG.cc:7243            void ReplicatedPG::repop_all_committed(RepGather *)
## // in_op->on_commit = ReplicatedPG::repop_all_committed(RepGather *)
## // invoked via InProgressOp->on_commit->complete(0)
## ReplicatedBackend.cc:732        void ReplicatedBackend::sub_op_modify_reply<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef)
## ReplicatedBackend.cc:221        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.882968 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] remove_repop repgather(0x7f6f6575b3c0 30'1 rep_tid=1901 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:1 t2.dat [writefull 0~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5)
##
## ReplicatedPG.cc:7509            void ReplicatedPG::remove_repop(RepGather *)
## ReplicatedPG.cc:7407            void ReplicatedPG::eval_repop(RepGather *)
## ReplicatedPG.cc:7243            void ReplicatedPG::repop_all_committed(RepGather *)
## // in_op->on_commit = ReplicatedPG::repop_all_committed(RepGather *)
## // invoked via InProgressOp->on_commit->complete(0)
## ReplicatedBackend.cc:732        void ReplicatedBackend::sub_op_modify_reply<MOSDRepOpReply, MSG_OSD_REPOPREPLY>(OpRequestRef)
## ReplicatedBackend.cc:221        bool ReplicatedBackend::handle_message(OpRequestRef)
## ReplicatedPG.cc:1274            void ReplicatedPG::do_request(OpRequestRef &, ThreadPool::TPHandle &)
## OSD.cc:8438                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.882973 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean]  obc obc(a3002fad/t2.dat/head//1 rwstate(write n=1 w=0))
##
## OSD.cc:8441                     void OSD::dequeue_op(PGRef, OpRequestRef, ThreadPool::TPHandle &)
## OSD.cc:8332                     void OSD::ShardedOpWQ::_process(uint32_t, heartbeat_handle_d *)
##
2015-11-23 08:48:50.883005 7f6f4336f700 10 osd.0 30 dequeue_op 0x7f6f64d2dd00 finish
##
## Processing of the next 4 MB chunk starts here
##
2015-11-23 08:48:50.896872 7f6f3a74c700 20 osd.0 30 should_share_map client.4141 10.253.0.2:0/1007850 30
2015-11-23 08:48:50.896894 7f6f3a74c700 15 osd.0 30 enqueue_op 0x7f6f64d2b100 prio 63 cost 4194304 latency 0.006778 osd_op(client.4141.0:2 t2.dat [write 4194304~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5
2015-11-23 08:48:50.896915 7f6f45b74700 10 osd.0 30 dequeue_op 0x7f6f64d2b100 prio 63 cost 4194304 latency 0.006799 osd_op(client.4141.0:2 t2.dat [write 4194304~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5 pg pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean]
2015-11-23 08:48:50.896930 7f6f45b74700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] op_has_sufficient_caps pool=1 (simple ) owner=0 need_read_cap=0 need_write_cap=1 need_class_read_cap=0 need_class_write_cap=0 -> yes
2015-11-23 08:48:50.896938 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] handle_message: 0x7f6f64d2b100
2015-11-23 08:48:50.896943 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] do_op osd_op(client.4141.0:2 t2.dat [write 4194304~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5 may_write -> write-ordered flags ondisk+write+known_if_redirected
2015-11-23 08:48:50.896957 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] get_object_context: found obc in cache: 0x7f6f65725e40
2015-11-23 08:48:50.896961 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] get_object_context: 0x7f6f65725e40 a3002fad/t2.dat/head//1 rwstate(none n=0 w=0) oi: a3002fad/t2.dat/head//1(30'1 client.4141.0:1 wrlock_by=unknown.0.0:0 dirty|data_digest|omap_digest s 4194304 uv 1 dd a172ec7b od ffffffff) ssc: 0x7f6f64d23fe0 snapset: 0=[]:[]+head
2015-11-23 08:48:50.896969 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] find_object_context a3002fad/t2.dat/head//1 @head oi=a3002fad/t2.dat/head//1(30'1 client.4141.0:1 wrlock_by=unknown.0.0:0 dirty|data_digest|omap_digest s 4194304 uv 1 dd a172ec7b od ffffffff)
2015-11-23 08:48:50.896983 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] execute_ctx 0x7f6f651ce400
2015-11-23 08:48:50.896988 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] do_op a3002fad/t2.dat/head//1 [write 4194304~4194304] ov 30'1 av 30'2 snapc 0=[] snapset 0=[]:[]+head
2015-11-23 08:48:50.896994 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] do_osd_op a3002fad/t2.dat/head//1 [write 4194304~4194304]
2015-11-23 08:48:50.896998 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] do_osd_op  write 4194304~4194304
2015-11-23 08:48:50.897029 7f6f45b74700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] make_writeable a3002fad/t2.dat/head//1 snapset=0x7f6f64d24020  snapc=0=[]
2015-11-23 08:48:50.897039 7f6f45b74700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] make_writeable a3002fad/t2.dat/head//1 done, snapset=0=[]:[]+head
2015-11-23 08:48:50.897043 7f6f45b74700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] finish_ctx a3002fad/t2.dat/head//1 0x7f6f651ce400 op modify  
2015-11-23 08:48:50.897049 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean]  set mtime to 2015-11-23 08:48:50.761596
2015-11-23 08:48:50.897059 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean]  final snapset 0=[]:[]+head in a3002fad/t2.dat/head//1
2015-11-23 08:48:50.897067 7f6f45b74700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean]  zeroing write result code 0
2015-11-23 08:48:50.897071 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] new_repop rep_tid 1902 on osd_op(client.4141.0:2 t2.dat [write 4194304~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5
2015-11-23 08:48:50.897077 7f6f45b74700  7 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] issue_repop rep_tid 1902 o a3002fad/t2.dat/head//1
2015-11-23 08:48:50.897122 7f6f45b74700 20 osd.0 30 share_map_peer 0x7f6f64eb9440 already has epoch 30
2015-11-23 08:48:50.897145 7f6f45b74700 20 osd.0 30 share_map_peer 0x7f6f65173080 already has epoch 30
2015-11-23 08:48:50.897158 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'1 (0'0,30'1] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] append_log log((0'0,30'1], crt=0'0) [30'2 (30'1) modify   a3002fad/t2.dat/head//1 by client.4141.0:2 2015-11-23 08:48:50.761596]
2015-11-23 08:48:50.897169 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 lua=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] add_log_entry 30'2 (30'1) modify   a3002fad/t2.dat/head//1 by client.4141.0:2 2015-11-23 08:48:50.761596
2015-11-23 08:48:50.897178 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 lua=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] append_log  adding 1 keys
2015-11-23 08:48:50.897184 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 lua=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] append_log: trimming to 0'0 entries 
2015-11-23 08:48:50.897197 7f6f45b74700 10 write_log with: dirty_to: 0'0, dirty_from: 4294967295'18446744073709551615, dirty_divergent_priors: 0, writeout_from: 30'2, trimmed: 
2015-11-23 08:48:50.897215 7f6f45b74700  5 filestore(/var/lib/ceph/osd/ceph-0) queue_transactions existing osr(1.2d 0x7f6f64cfdee0)/0x7f6f64cfdee0
2015-11-23 08:48:50.897223 7f6f45b74700 10 journal op_submit_start 2666
2015-11-23 08:48:50.897224 7f6f45b74700  5 filestore(/var/lib/ceph/osd/ceph-0) queue_transactions (writeahead) 2666 0x7f6f657dfc00
2015-11-23 08:48:50.897225 7f6f45b74700 10 journal op_journal_transactions 2666 0x7f6f657dfc00
2015-11-23 08:48:50.897228 7f6f45b74700  5 journal submit_entry seq 2666 len 4196455 (0x7f6f66793a70)
2015-11-23 08:48:50.897254 7f6f45b74700 10 journal op_submit_finish 2666
2015-11-23 08:48:50.897256 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 lua=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] eval_repop repgather(0x7f6f6638c640 30'2 rep_tid=1902 committed?=0 applied?=0 lock=0 op=osd_op(client.4141.0:2 t2.dat [write 4194304~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) wants=d
2015-11-23 08:48:50.897264 7f6f45b74700 10 osd.0 30 dequeue_op 0x7f6f64d2b100 finish
2015-11-23 08:48:50.899879 7f6f554e2700 20 journal write_thread_entry woke up
2015-11-23 08:48:50.899979 7f6f554e2700 10 journal room 5364494335 max_size 5368709120 pos 31993856 header.start 27783168 top 4096
2015-11-23 08:48:50.900007 7f6f554e2700 10 journal check_for_full at 31993856 : 4202496 < 5364494335
2015-11-23 08:48:50.900031 7f6f554e2700 15 journal prepare_single_write 1 will write 31993856 : seq 2666 len 4196455 -> 4202496 (head 40 pre_pad 4046 ebl 4196455 post_pad 1915 tail 40) (ebl alignment 4086)
2015-11-23 08:48:50.902552 7f6f554e2700 20 journal prepare_multi_write queue_pos now 36196352
2015-11-23 08:48:50.902632 7f6f554e2700 15 journal do_aio_write writing 31993856~4202496
2015-11-23 08:48:50.903551 7f6f554e2700 10 journal align_bl total memcopy: 4202496
2015-11-23 08:48:50.903640 7f6f554e2700 20 journal write_aio_bl 31993856~4202496 seq 2666
2015-11-23 08:48:50.903669 7f6f554e2700 20 journal write_aio_bl .. 31993856~4202496 in 1
2015-11-23 08:48:50.903769 7f6f55ce3700 10 filestore(/var/lib/ceph/osd/ceph-0) sync_entry commit took 0.221161, interval was 5.221299
2015-11-23 08:48:50.903785 7f6f55ce3700 10 journal commit_finish thru 2664
2015-11-23 08:48:50.904028 7f6f554e2700  5 journal put_throttle finished 1 ops and 4196455 bytes, now 0 ops and 0 bytes
2015-11-23 08:48:50.904060 7f6f554e2700 20 journal write_thread_entry going to sleep
2015-11-23 08:48:50.904125 7f6f54ce1700 20 journal write_finish_thread_entry waiting for aio(s)
2015-11-23 08:48:50.904139 7f6f55ce3700  5 journal committed_thru 2664 (last_committed_seq 2663)
2015-11-23 08:48:50.904143 7f6f55ce3700 10 journal header: block_size 4096 alignment 4096 max_size 5368709120
2015-11-23 08:48:50.904144 7f6f55ce3700 10 journal header: start 27791360
2015-11-23 08:48:50.904145 7f6f55ce3700 10 journal  write_pos 36196352
2015-11-23 08:48:50.904146 7f6f55ce3700 10 journal committed_thru done
2015-11-23 08:48:50.904154 7f6f55ce3700 15 filestore(/var/lib/ceph/osd/ceph-0) sync_entry committed to op_seq 2664
2015-11-23 08:48:50.904160 7f6f55ce3700 20 filestore(/var/lib/ceph/osd/ceph-0) sync_entry waiting for max_interval 5.000000
2015-11-23 08:48:51.069159 7f6f54ce1700 10 journal write_finish_thread_entry aio 31993856~4202496 done
2015-11-23 08:48:51.069179 7f6f54ce1700 20 journal check_aio_completion
2015-11-23 08:48:51.069180 7f6f54ce1700 20 journal check_aio_completion completed seq 2666 31993856~4202496
2015-11-23 08:48:51.069199 7f6f54ce1700 20 journal check_aio_completion queueing finishers through seq 2666
2015-11-23 08:48:51.069202 7f6f54ce1700 10 journal queue_completions_thru seq 2666 queueing seq 2666 0x7f6f66793a70 lat 0.171963
2015-11-23 08:48:51.069223 7f6f54ce1700 20 journal write_finish_thread_entry sleeping
2015-11-23 08:48:51.069234 7f6f544e0700  5 filestore(/var/lib/ceph/osd/ceph-0) _journaled_ahead 0x7f6f65985b60 seq 2666 osr(1.2d 0x7f6f64cfdee0) 0x7f6f657dfc00
2015-11-23 08:48:51.069238 7f6f544e0700  5 filestore(/var/lib/ceph/osd/ceph-0) queue_op 0x7f6f65985b60 seq 2666 osr(1.2d 0x7f6f64cfdee0) 4196441 bytes   (queue has 1 ops and 4196441 bytes)
2015-11-23 08:48:51.069247 7f6f544e0700 10 filestore(/var/lib/ceph/osd/ceph-0)  queueing ondisk 0x7f6f664ac4c0
2015-11-23 08:48:51.069253 7f6f524dc700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 lua=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] op_commit: 1902
2015-11-23 08:48:51.069264 7f6f53cdf700 10 journal op_apply_start 2666 open_ops 0 -> 1
2015-11-23 08:48:51.069270 7f6f53cdf700  5 filestore(/var/lib/ceph/osd/ceph-0) _do_op 0x7f6f65985b60 seq 2666 osr(1.2d 0x7f6f64cfdee0)/0x7f6f64cfdee0 start
2015-11-23 08:48:51.069272 7f6f53cdf700 10 filestore(/var/lib/ceph/osd/ceph-0) _do_transaction on 0x7f6f657dfc00
2015-11-23 08:48:51.069284 7f6f53cdf700 15 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1
2015-11-23 08:48:51.069313 7f6f53cdf700 10 filestore oid: 2d//head//1 not skipping op, *spos 2666.0.0
2015-11-23 08:48:51.069314 7f6f53cdf700 10 filestore  > header.spos 0.0.0
2015-11-23 08:48:51.069348 7f6f53cdf700 20 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1 = 0
2015-11-23 08:48:51.069353 7f6f53cdf700 15 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1
2015-11-23 08:48:51.069361 7f6f53cdf700 10 filestore oid: 2d//head//1 not skipping op, *spos 2666.0.1
2015-11-23 08:48:51.069362 7f6f53cdf700 10 filestore  > header.spos 0.0.0
2015-11-23 08:48:51.069374 7f6f53cdf700 20 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1 = 0
2015-11-23 08:48:51.069378 7f6f53cdf700 15 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1
2015-11-23 08:48:51.069385 7f6f53cdf700 10 filestore oid: 2d//head//1 not skipping op, *spos 2666.0.2
2015-11-23 08:48:51.069386 7f6f53cdf700 10 filestore  > header.spos 0.0.0
2015-11-23 08:48:51.069399 7f6f53cdf700 20 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1 = 0
2015-11-23 08:48:51.069402 7f6f53cdf700 15 filestore(/var/lib/ceph/osd/ceph-0) write 1.2d_head/a3002fad/t2.dat/head//1 4194304~4194304
2015-11-23 08:48:51.071038 7f6f53cdf700 10 filestore(/var/lib/ceph/osd/ceph-0) write 1.2d_head/a3002fad/t2.dat/head//1 4194304~4194304 = 4194304
2015-11-23 08:48:51.071075 7f6f53cdf700 20 filestore(/var/lib/ceph/osd/ceph-0) fgetattrs 145 getting '_'
2015-11-23 08:48:51.071080 7f6f53cdf700 20 filestore(/var/lib/ceph/osd/ceph-0) fgetattrs 145 getting 'snapset'
2015-11-23 08:48:51.071082 7f6f53cdf700 15 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1
2015-11-23 08:48:51.071113 7f6f53cdf700 10 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1 = 0
2015-11-23 08:48:51.071120 7f6f53cdf700 20 filestore(/var/lib/ceph/osd/ceph-0) fgetattrs 145 getting '_'
2015-11-23 08:48:51.071123 7f6f53cdf700 20 filestore(/var/lib/ceph/osd/ceph-0) fgetattrs 145 getting 'snapset'
2015-11-23 08:48:51.071124 7f6f53cdf700 15 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1
2015-11-23 08:48:51.071129 7f6f53cdf700 10 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1 = 0
2015-11-23 08:48:51.071131 7f6f53cdf700 10 journal op_apply_finish 2666 open_ops 1 -> 0, max_applied_seq 2665 -> 2666
2015-11-23 08:48:51.071132 7f6f53cdf700 10 filestore(/var/lib/ceph/osd/ceph-0) _do_op 0x7f6f65985b60 seq 2666 r = 0, finisher 0x7f6f664ab700 0x7f6f66129c80
2015-11-23 08:48:51.071135 7f6f53cdf700 10 filestore(/var/lib/ceph/osd/ceph-0) _finish_op 0x7f6f65985b60 seq 2666 osr(1.2d 0x7f6f64cfdee0)/0x7f6f64cfdee0
2015-11-23 08:48:51.071311 7f6f52cdd700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 lua=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] op_applied: 1902
2015-11-23 08:48:51.071339 7f6f52cdd700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 lua=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] op_applied version 30'2
2015-11-23 08:48:51.099519 7f6f3b85d700 10 osd.0 30 handle_replica_op osd_repop_reply(client.4141.0:2 1.2d ondisk, result = 0) v1 epoch 30
2015-11-23 08:48:51.099523 7f6f3b85d700 20 osd.0 30 should_share_map osd.1 10.253.0.4:6801/3119 30
2015-11-23 08:48:51.099527 7f6f3b85d700 15 osd.0 30 enqueue_op 0x7f6f64d2df00 prio 196 cost 0 latency 0.000125 osd_repop_reply(client.4141.0:2 1.2d ondisk, result = 0) v1
2015-11-23 08:48:51.099552 7f6f4336f700 10 osd.0 30 dequeue_op 0x7f6f64d2df00 prio 196 cost 0 latency 0.000150 osd_repop_reply(client.4141.0:2 1.2d ondisk, result = 0) v1 pg pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean]
2015-11-23 08:48:51.099566 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] handle_message: 0x7f6f64d2df00
2015-11-23 08:48:51.099574 7f6f4336f700  7 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] sub_op_modify_reply: tid 1902 op  ack_type 4 from 1
2015-11-23 08:48:51.099585 7f6f3aa4f700 10 osd.0 30 handle_replica_op osd_repop_reply(client.4141.0:2 1.2d ondisk, result = 0) v1 epoch 30
2015-11-23 08:48:51.099588 7f6f3aa4f700 20 osd.0 30 should_share_map osd.2 10.253.0.5:6801/3128 30
2015-11-23 08:48:51.099591 7f6f3aa4f700 15 osd.0 30 enqueue_op 0x7f6f64d2c300 prio 196 cost 0 latency 0.000056 osd_repop_reply(client.4141.0:2 1.2d ondisk, result = 0) v1
2015-11-23 08:48:51.099596 7f6f4336f700 10 osd.0 30 dequeue_op 0x7f6f64d2df00 finish
2015-11-23 08:48:51.099614 7f6f4336f700 10 osd.0 30 dequeue_op 0x7f6f64d2c300 prio 196 cost 0 latency 0.000079 osd_repop_reply(client.4141.0:2 1.2d ondisk, result = 0) v1 pg pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean]
2015-11-23 08:48:51.099621 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] handle_message: 0x7f6f64d2c300
2015-11-23 08:48:51.099626 7f6f4336f700  7 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] sub_op_modify_reply: tid 1902 op  ack_type 4 from 2
2015-11-23 08:48:51.099634 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] repop_all_applied: repop tid 1902 all applied 
2015-11-23 08:48:51.099638 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] eval_repop repgather(0x7f6f6638c640 30'2 rep_tid=1902 committed?=0 applied?=1 lock=0 op=osd_op(client.4141.0:2 t2.dat [write 4194304~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) wants=d
2015-11-23 08:48:51.099647 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'1 crt=0'0 lcod 0'0 mlcod 0'0 active+clean] repop_all_committed: repop tid 1902 all committed 
2015-11-23 08:48:51.099650 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 0'0 active+clean] eval_repop repgather(0x7f6f6638c640 30'2 rep_tid=1902 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:2 t2.dat [write 4194304~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) wants=d
2015-11-23 08:48:51.099656 7f6f4336f700 15 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 0'0 active+clean] log_op_stats osd_op(client.4141.0:2 t2.dat [write 4194304~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5 inb 4194304 outb 0 rlat 0.209531 lat 0.209540
2015-11-23 08:48:51.099663 7f6f4336f700 15 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 0'0 active+clean] publish_stats_to_osd 30:14
2015-11-23 08:48:51.099667 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 0'0 active+clean]  sending commit on repgather(0x7f6f6638c640 30'2 rep_tid=1902 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:2 t2.dat [write 4194304~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) 0x7f6f669ba580
2015-11-23 08:48:51.099688 7f6f4336f700 15 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 0'0 active+clean] do_osd_op_effects client.4141 con 0x7f6f66884680
2015-11-23 08:48:51.099693 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean]  removing repgather(0x7f6f6638c640 30'2 rep_tid=1902 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:2 t2.dat [write 4194304~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5)
2015-11-23 08:48:51.099698 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean]    q front is repgather(0x7f6f6638c640 30'2 rep_tid=1902 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:2 t2.dat [write 4194304~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5)
2015-11-23 08:48:51.099703 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] remove_repop repgather(0x7f6f6638c640 30'2 rep_tid=1902 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:2 t2.dat [write 4194304~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5)
2015-11-23 08:48:51.099708 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean]  obc obc(a3002fad/t2.dat/head//1 rwstate(write n=1 w=0))
2015-11-23 08:48:51.099725 7f6f4336f700 10 osd.0 30 dequeue_op 0x7f6f64d2c300 finish
2015-11-23 08:48:51.117049 7f6f3a74c700 20 osd.0 30 should_share_map client.4141 10.253.0.2:0/1007850 30
2015-11-23 08:48:51.117092 7f6f3a74c700 15 osd.0 30 enqueue_op 0x7f6f64d2bf00 prio 63 cost 4194304 latency 0.012235 osd_op(client.4141.0:3 t2.dat [write 8388608~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5
2015-11-23 08:48:51.117123 7f6f4336f700 10 osd.0 30 dequeue_op 0x7f6f64d2bf00 prio 63 cost 4194304 latency 0.012266 osd_op(client.4141.0:3 t2.dat [write 8388608~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5 pg pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean]
2015-11-23 08:48:51.117147 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] op_has_sufficient_caps pool=1 (simple ) owner=0 need_read_cap=0 need_write_cap=1 need_class_read_cap=0 need_class_write_cap=0 -> yes
2015-11-23 08:48:51.117160 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] handle_message: 0x7f6f64d2bf00
2015-11-23 08:48:51.117168 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] do_op osd_op(client.4141.0:3 t2.dat [write 8388608~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5 may_write -> write-ordered flags ondisk+write+known_if_redirected
2015-11-23 08:48:51.117189 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] get_object_context: found obc in cache: 0x7f6f65725e40
2015-11-23 08:48:51.117197 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] get_object_context: 0x7f6f65725e40 a3002fad/t2.dat/head//1 rwstate(none n=0 w=0) oi: a3002fad/t2.dat/head//1(30'2 client.4141.0:2 wrlock_by=unknown.0.0:0 dirty|omap_digest s 8388608 uv 2 od ffffffff) ssc: 0x7f6f64d23fe0 snapset: 0=[]:[]+head
2015-11-23 08:48:51.117210 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] find_object_context a3002fad/t2.dat/head//1 @head oi=a3002fad/t2.dat/head//1(30'2 client.4141.0:2 wrlock_by=unknown.0.0:0 dirty|omap_digest s 8388608 uv 2 od ffffffff)
2015-11-23 08:48:51.117231 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] execute_ctx 0x7f6f651ce400
2015-11-23 08:48:51.117241 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] do_op a3002fad/t2.dat/head//1 [write 8388608~4194304] ov 30'2 av 30'3 snapc 0=[] snapset 0=[]:[]+head
2015-11-23 08:48:51.117251 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] do_osd_op a3002fad/t2.dat/head//1 [write 8388608~4194304]
2015-11-23 08:48:51.117259 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] do_osd_op  write 8388608~4194304
2015-11-23 08:48:51.117277 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] make_writeable a3002fad/t2.dat/head//1 snapset=0x7f6f64d24020  snapc=0=[]
2015-11-23 08:48:51.117289 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] make_writeable a3002fad/t2.dat/head//1 done, snapset=0=[]:[]+head
2015-11-23 08:48:51.117296 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] finish_ctx a3002fad/t2.dat/head//1 0x7f6f651ce400 op modify  
2015-11-23 08:48:51.117306 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean]  set mtime to 2015-11-23 08:48:50.976052
2015-11-23 08:48:51.117335 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean]  final snapset 0=[]:[]+head in a3002fad/t2.dat/head//1
2015-11-23 08:48:51.117348 7f6f4336f700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean]  zeroing write result code 0
2015-11-23 08:48:51.117356 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] new_repop rep_tid 1903 on osd_op(client.4141.0:3 t2.dat [write 8388608~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5
2015-11-23 08:48:51.117366 7f6f4336f700  7 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] issue_repop rep_tid 1903 o a3002fad/t2.dat/head//1
2015-11-23 08:48:51.117407 7f6f4336f700 20 osd.0 30 share_map_peer 0x7f6f64eb9440 already has epoch 30
2015-11-23 08:48:51.117432 7f6f4336f700 20 osd.0 30 share_map_peer 0x7f6f65173080 already has epoch 30
2015-11-23 08:48:51.117443 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'2 (0'0,30'2] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] append_log log((0'0,30'2], crt=0'0) [30'3 (30'2) modify   a3002fad/t2.dat/head//1 by client.4141.0:3 2015-11-23 08:48:50.976052]
2015-11-23 08:48:51.117461 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'2 lua=30'2 crt=0'0 lcod 30'1 mlcod 30'1 active+clean] add_log_entry 30'3 (30'2) modify   a3002fad/t2.dat/head//1 by client.4141.0:3 2015-11-23 08:48:50.976052
2015-11-23 08:48:51.117477 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'2 lua=30'2 crt=30'1 lcod 30'1 mlcod 30'1 active+clean] append_log  adding 1 keys
2015-11-23 08:48:51.117488 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'2 lua=30'2 crt=30'1 lcod 30'1 mlcod 30'1 active+clean] append_log: trimming to 30'1 entries 30'1 (0'0) modify   a3002fad/t2.dat/head//1 by client.4141.0:1 2015-11-23 08:48:50.476478
2015-11-23 08:48:51.117515 7f6f4336f700 10 write_log with: dirty_to: 0'0, dirty_from: 4294967295'18446744073709551615, dirty_divergent_priors: 0, writeout_from: 30'3, trimmed: 
2015-11-23 08:48:51.117537 7f6f4336f700  5 filestore(/var/lib/ceph/osd/ceph-0) queue_transactions existing osr(1.2d 0x7f6f64cfdee0)/0x7f6f64cfdee0
2015-11-23 08:48:51.117548 7f6f4336f700 10 journal op_submit_start 2667
2015-11-23 08:48:51.117550 7f6f4336f700  5 filestore(/var/lib/ceph/osd/ceph-0) queue_transactions (writeahead) 2667 0x7f6f657e0300
2015-11-23 08:48:51.117552 7f6f4336f700 10 journal op_journal_transactions 2667 0x7f6f657e0300
2015-11-23 08:48:51.117557 7f6f4336f700  5 journal submit_entry seq 2667 len 4196455 (0x7f6f66c469d0)
2015-11-23 08:48:51.117599 7f6f4336f700 10 journal op_submit_finish 2667
2015-11-23 08:48:51.117603 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'2 lua=30'2 crt=30'1 lcod 30'1 mlcod 30'1 active+clean] eval_repop repgather(0x7f6f661d5e40 30'3 rep_tid=1903 committed?=0 applied?=0 lock=0 op=osd_op(client.4141.0:3 t2.dat [write 8388608~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) wants=d
2015-11-23 08:48:51.117625 7f6f4336f700 10 osd.0 30 dequeue_op 0x7f6f64d2bf00 finish
2015-11-23 08:48:51.118429 7f6f554e2700 20 journal write_thread_entry woke up
2015-11-23 08:48:51.118484 7f6f554e2700 10 journal room 5360300031 max_size 5368709120 pos 36196352 header.start 27791360 top 4096
2015-11-23 08:48:51.118531 7f6f554e2700 10 journal check_for_full at 36196352 : 4202496 < 5360300031
2015-11-23 08:48:51.118575 7f6f554e2700 15 journal prepare_single_write 1 will write 36196352 : seq 2667 len 4196455 -> 4202496 (head 40 pre_pad 4046 ebl 4196455 post_pad 1915 tail 40) (ebl alignment 4086)
2015-11-23 08:48:51.122178 7f6f554e2700 20 journal prepare_multi_write queue_pos now 40398848
2015-11-23 08:48:51.122245 7f6f554e2700 15 journal do_aio_write writing 36196352~4202496 + header
2015-11-23 08:48:51.122292 7f6f554e2700 20 journal write_aio_bl 0~4096 seq 0
2015-11-23 08:48:51.122348 7f6f554e2700 20 journal write_aio_bl .. 0~4096 in 1
2015-11-23 08:48:51.123367 7f6f554e2700 10 journal align_bl total memcopy: 4202496
2015-11-23 08:48:51.123474 7f6f554e2700 20 journal write_aio_bl 36196352~4202496 seq 2667
2015-11-23 08:48:51.123522 7f6f554e2700 20 journal write_aio_bl .. 36196352~4202496 in 1
2015-11-23 08:48:51.124116 7f6f554e2700  5 journal put_throttle finished 1 ops and 4196455 bytes, now 0 ops and 0 bytes
2015-11-23 08:48:51.124122 7f6f54ce1700 20 journal write_finish_thread_entry waiting for aio(s)
2015-11-23 08:48:51.124226 7f6f554e2700 20 journal write_thread_entry going to sleep
2015-11-23 08:48:51.134566 7f6f54ce1700 10 journal write_finish_thread_entry aio 0~4096 done
2015-11-23 08:48:51.134586 7f6f54ce1700 20 journal check_aio_completion
2015-11-23 08:48:51.134587 7f6f54ce1700 20 journal check_aio_completion completed seq 0 0~4096
2015-11-23 08:48:51.134593 7f6f54ce1700 20 journal write_finish_thread_entry waiting for aio(s)
2015-11-23 08:48:51.299057 7f6f54ce1700 10 journal write_finish_thread_entry aio 36196352~4202496 done
2015-11-23 08:48:51.299079 7f6f54ce1700 20 journal check_aio_completion
2015-11-23 08:48:51.299081 7f6f54ce1700 20 journal check_aio_completion completed seq 2667 36196352~4202496
2015-11-23 08:48:51.299087 7f6f54ce1700 20 journal check_aio_completion queueing finishers through seq 2667
2015-11-23 08:48:51.299089 7f6f54ce1700 10 journal queue_completions_thru seq 2667 queueing seq 2667 0x7f6f66c469d0 lat 0.181521
2015-11-23 08:48:51.299115 7f6f544e0700  5 filestore(/var/lib/ceph/osd/ceph-0) _journaled_ahead 0x7f6f64f85450 seq 2667 osr(1.2d 0x7f6f64cfdee0) 0x7f6f657e0300
2015-11-23 08:48:51.299122 7f6f544e0700  5 filestore(/var/lib/ceph/osd/ceph-0) queue_op 0x7f6f64f85450 seq 2667 osr(1.2d 0x7f6f64cfdee0) 4196441 bytes   (queue has 1 ops and 4196441 bytes)
2015-11-23 08:48:51.299131 7f6f544e0700 10 filestore(/var/lib/ceph/osd/ceph-0)  queueing ondisk 0x7f6f66beae80
2015-11-23 08:48:51.299139 7f6f524dc700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'2 lua=30'2 crt=30'1 lcod 30'1 mlcod 30'1 active+clean] op_commit: 1903
2015-11-23 08:48:51.299164 7f6f54ce1700 20 journal write_finish_thread_entry sleeping
2015-11-23 08:48:51.299177 7f6f534de700 10 journal op_apply_start 2667 open_ops 0 -> 1
2015-11-23 08:48:51.299179 7f6f534de700  5 filestore(/var/lib/ceph/osd/ceph-0) _do_op 0x7f6f64f85450 seq 2667 osr(1.2d 0x7f6f64cfdee0)/0x7f6f64cfdee0 start
2015-11-23 08:48:51.299181 7f6f534de700 10 filestore(/var/lib/ceph/osd/ceph-0) _do_transaction on 0x7f6f657e0300
2015-11-23 08:48:51.299195 7f6f534de700 15 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1
2015-11-23 08:48:51.299226 7f6f534de700 10 filestore oid: 2d//head//1 not skipping op, *spos 2667.0.0
2015-11-23 08:48:51.299227 7f6f534de700 10 filestore  > header.spos 0.0.0
2015-11-23 08:48:51.299261 7f6f534de700 20 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1 = 0
2015-11-23 08:48:51.299266 7f6f534de700 15 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1
2015-11-23 08:48:51.299277 7f6f534de700 10 filestore oid: 2d//head//1 not skipping op, *spos 2667.0.1
2015-11-23 08:48:51.299278 7f6f534de700 10 filestore  > header.spos 0.0.0
2015-11-23 08:48:51.299295 7f6f534de700 20 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1 = 0
2015-11-23 08:48:51.299299 7f6f534de700 15 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1
2015-11-23 08:48:51.299308 7f6f534de700 10 filestore oid: 2d//head//1 not skipping op, *spos 2667.0.2
2015-11-23 08:48:51.299309 7f6f534de700 10 filestore  > header.spos 0.0.0
2015-11-23 08:48:51.299335 7f6f534de700 20 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1 = 0
2015-11-23 08:48:51.299339 7f6f534de700 15 filestore(/var/lib/ceph/osd/ceph-0) write 1.2d_head/a3002fad/t2.dat/head//1 8388608~4194304
2015-11-23 08:48:51.301224 7f6f3aa4f700 10 osd.0 30 handle_replica_op osd_repop_reply(client.4141.0:3 1.2d ondisk, result = 0) v1 epoch 30
2015-11-23 08:48:51.301229 7f6f3aa4f700 20 osd.0 30 should_share_map osd.2 10.253.0.5:6801/3128 30
2015-11-23 08:48:51.301234 7f6f3aa4f700 15 osd.0 30 enqueue_op 0x7f6f64d2c400 prio 196 cost 0 latency 0.000131 osd_repop_reply(client.4141.0:3 1.2d ondisk, result = 0) v1
2015-11-23 08:48:51.301270 7f6f45b74700 10 osd.0 30 dequeue_op 0x7f6f64d2c400 prio 196 cost 0 latency 0.000166 osd_repop_reply(client.4141.0:3 1.2d ondisk, result = 0) v1 pg pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'2 lua=30'2 crt=30'1 lcod 30'1 mlcod 30'1 active+clean]
2015-11-23 08:48:51.301292 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'2 lua=30'2 crt=30'1 lcod 30'1 mlcod 30'1 active+clean] handle_message: 0x7f6f64d2c400
2015-11-23 08:48:51.301302 7f6f45b74700  7 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'2 lua=30'2 crt=30'1 lcod 30'1 mlcod 30'1 active+clean] sub_op_modify_reply: tid 1903 op  ack_type 4 from 2
2015-11-23 08:48:51.301316 7f6f45b74700 10 osd.0 30 dequeue_op 0x7f6f64d2c400 finish
2015-11-23 08:48:51.301418 7f6f3b85d700 10 osd.0 30 handle_replica_op osd_repop_reply(client.4141.0:3 1.2d ondisk, result = 0) v1 epoch 30
2015-11-23 08:48:51.301420 7f6f3b85d700 20 osd.0 30 should_share_map osd.1 10.253.0.4:6801/3119 30
2015-11-23 08:48:51.301424 7f6f3b85d700 15 osd.0 30 enqueue_op 0x7f6f64d2c000 prio 196 cost 0 latency 0.000066 osd_repop_reply(client.4141.0:3 1.2d ondisk, result = 0) v1
2015-11-23 08:48:51.301439 7f6f4336f700 10 osd.0 30 dequeue_op 0x7f6f64d2c000 prio 196 cost 0 latency 0.000081 osd_repop_reply(client.4141.0:3 1.2d ondisk, result = 0) v1 pg pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'2 lua=30'2 crt=30'1 lcod 30'1 mlcod 30'1 active+clean]
2015-11-23 08:48:51.301448 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'2 lua=30'2 crt=30'1 lcod 30'1 mlcod 30'1 active+clean] handle_message: 0x7f6f64d2c000
2015-11-23 08:48:51.301456 7f6f4336f700  7 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'2 lua=30'2 crt=30'1 lcod 30'1 mlcod 30'1 active+clean] sub_op_modify_reply: tid 1903 op  ack_type 4 from 1
2015-11-23 08:48:51.301466 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'2 lua=30'2 crt=30'1 lcod 30'1 mlcod 30'1 active+clean] repop_all_committed: repop tid 1903 all committed 
2015-11-23 08:48:51.301471 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 lua=30'2 crt=30'1 lcod 30'2 mlcod 30'1 active+clean] eval_repop repgather(0x7f6f661d5e40 30'3 rep_tid=1903 committed?=1 applied?=0 lock=0 op=osd_op(client.4141.0:3 t2.dat [write 8388608~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) wants=d
2015-11-23 08:48:51.301480 7f6f4336f700 15 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 lua=30'2 crt=30'1 lcod 30'2 mlcod 30'1 active+clean] log_op_stats osd_op(client.4141.0:3 t2.dat [write 8388608~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5 inb 4194304 outb 0 rlat 0.000000 lat 0.196622
2015-11-23 08:48:51.301488 7f6f4336f700 15 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 lua=30'2 crt=30'1 lcod 30'2 mlcod 30'1 active+clean] publish_stats_to_osd 30:15
2015-11-23 08:48:51.301493 7f6f4336f700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 lua=30'2 crt=30'1 lcod 30'2 mlcod 30'1 active+clean]  sending commit on repgather(0x7f6f661d5e40 30'3 rep_tid=1903 committed?=1 applied?=0 lock=0 op=osd_op(client.4141.0:3 t2.dat [write 8388608~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) 0x7f6f657263c0
2015-11-23 08:48:51.301513 7f6f4336f700 10 osd.0 30 dequeue_op 0x7f6f64d2c000 finish
2015-11-23 08:48:51.301732 7f6f534de700 10 filestore(/var/lib/ceph/osd/ceph-0) write 1.2d_head/a3002fad/t2.dat/head//1 8388608~4194304 = 4194304
2015-11-23 08:48:51.301765 7f6f534de700 20 filestore(/var/lib/ceph/osd/ceph-0) fgetattrs 145 getting '_'
2015-11-23 08:48:51.301770 7f6f534de700 20 filestore(/var/lib/ceph/osd/ceph-0) fgetattrs 145 getting 'snapset'
2015-11-23 08:48:51.301772 7f6f534de700 15 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1
2015-11-23 08:48:51.301793 7f6f534de700 10 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1 = 0
2015-11-23 08:48:51.301800 7f6f534de700 20 filestore(/var/lib/ceph/osd/ceph-0) fgetattrs 145 getting '_'
2015-11-23 08:48:51.301803 7f6f534de700 20 filestore(/var/lib/ceph/osd/ceph-0) fgetattrs 145 getting 'snapset'
2015-11-23 08:48:51.301805 7f6f534de700 15 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1
2015-11-23 08:48:51.301811 7f6f534de700 10 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1 = 0
2015-11-23 08:48:51.301814 7f6f534de700 10 journal op_apply_finish 2667 open_ops 1 -> 0, max_applied_seq 2666 -> 2667
2015-11-23 08:48:51.301815 7f6f534de700 10 filestore(/var/lib/ceph/osd/ceph-0) _do_op 0x7f6f64f85450 seq 2667 r = 0, finisher 0x7f6f665283c0 0x7f6f668ccdc0
2015-11-23 08:48:51.301818 7f6f534de700 10 filestore(/var/lib/ceph/osd/ceph-0) _finish_op 0x7f6f64f85450 seq 2667 osr(1.2d 0x7f6f64cfdee0)/0x7f6f64cfdee0
2015-11-23 08:48:51.301832 7f6f52cdd700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 lua=30'2 crt=30'1 lcod 30'2 mlcod 30'1 active+clean] op_applied: 1903
2015-11-23 08:48:51.301846 7f6f52cdd700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 lua=30'2 crt=30'1 lcod 30'2 mlcod 30'1 active+clean] op_applied version 30'3
2015-11-23 08:48:51.301853 7f6f52cdd700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'1 active+clean] repop_all_applied: repop tid 1903 all applied 
2015-11-23 08:48:51.301857 7f6f52cdd700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'1 active+clean] eval_repop repgather(0x7f6f661d5e40 30'3 rep_tid=1903 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:3 t2.dat [write 8388608~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) wants=d
2015-11-23 08:48:51.301865 7f6f52cdd700 15 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'1 active+clean] publish_stats_to_osd 30: no change since
2015-11-23 08:48:51.301877 7f6f52cdd700 15 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'1 active+clean] do_osd_op_effects client.4141 con 0x7f6f66884680
2015-11-23 08:48:51.301883 7f6f52cdd700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean]  removing repgather(0x7f6f661d5e40 30'3 rep_tid=1903 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:3 t2.dat [write 8388608~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5)
2015-11-23 08:48:51.301889 7f6f52cdd700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean]    q front is repgather(0x7f6f661d5e40 30'3 rep_tid=1903 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:3 t2.dat [write 8388608~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5)
2015-11-23 08:48:51.301895 7f6f52cdd700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] remove_repop repgather(0x7f6f661d5e40 30'3 rep_tid=1903 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:3 t2.dat [write 8388608~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5)
2015-11-23 08:48:51.301901 7f6f52cdd700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean]  obc obc(a3002fad/t2.dat/head//1 rwstate(write n=1 w=0))
2015-11-23 08:48:51.313499 7f6f3a74c700 20 osd.0 30 should_share_map client.4141 10.253.0.2:0/1007850 30
2015-11-23 08:48:51.313579 7f6f3a74c700 15 osd.0 30 enqueue_op 0x7f6f64d2b200 prio 63 cost 4194304 latency 0.006190 osd_op(client.4141.0:4 t2.dat [write 12582912~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5
2015-11-23 08:48:51.313653 7f6f45b74700 10 osd.0 30 dequeue_op 0x7f6f64d2b200 prio 63 cost 4194304 latency 0.006264 osd_op(client.4141.0:4 t2.dat [write 12582912~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5 pg pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean]
2015-11-23 08:48:51.313689 7f6f45b74700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] op_has_sufficient_caps pool=1 (simple ) owner=0 need_read_cap=0 need_write_cap=1 need_class_read_cap=0 need_class_write_cap=0 -> yes
2015-11-23 08:48:51.313698 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] handle_message: 0x7f6f64d2b200
2015-11-23 08:48:51.313704 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] do_op osd_op(client.4141.0:4 t2.dat [write 12582912~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5 may_write -> write-ordered flags ondisk+write+known_if_redirected
2015-11-23 08:48:51.313719 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] get_object_context: found obc in cache: 0x7f6f65725e40
2015-11-23 08:48:51.313723 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] get_object_context: 0x7f6f65725e40 a3002fad/t2.dat/head//1 rwstate(none n=0 w=0) oi: a3002fad/t2.dat/head//1(30'3 client.4141.0:3 wrlock_by=unknown.0.0:0 dirty|omap_digest s 12582912 uv 3 od ffffffff) ssc: 0x7f6f64d23fe0 snapset: 0=[]:[]+head
2015-11-23 08:48:51.313732 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] find_object_context a3002fad/t2.dat/head//1 @head oi=a3002fad/t2.dat/head//1(30'3 client.4141.0:3 wrlock_by=unknown.0.0:0 dirty|omap_digest s 12582912 uv 3 od ffffffff)
2015-11-23 08:48:51.313747 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] execute_ctx 0x7f6f651cde00
2015-11-23 08:48:51.313754 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] do_op a3002fad/t2.dat/head//1 [write 12582912~4194304] ov 30'3 av 30'4 snapc 0=[] snapset 0=[]:[]+head
2015-11-23 08:48:51.313760 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] do_osd_op a3002fad/t2.dat/head//1 [write 12582912~4194304]
2015-11-23 08:48:51.313764 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] do_osd_op  write 12582912~4194304
2015-11-23 08:48:51.313780 7f6f45b74700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] make_writeable a3002fad/t2.dat/head//1 snapset=0x7f6f64d24020  snapc=0=[]
2015-11-23 08:48:51.313788 7f6f45b74700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] make_writeable a3002fad/t2.dat/head//1 done, snapset=0=[]:[]+head
2015-11-23 08:48:51.313799 7f6f45b74700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] finish_ctx a3002fad/t2.dat/head//1 0x7f6f651cde00 op modify  
2015-11-23 08:48:51.313805 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean]  set mtime to 2015-11-23 08:48:51.178421
2015-11-23 08:48:51.313816 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean]  final snapset 0=[]:[]+head in a3002fad/t2.dat/head//1
2015-11-23 08:48:51.313829 7f6f45b74700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean]  zeroing write result code 0
2015-11-23 08:48:51.313834 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] new_repop rep_tid 1904 on osd_op(client.4141.0:4 t2.dat [write 12582912~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5
2015-11-23 08:48:51.313840 7f6f45b74700  7 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] issue_repop rep_tid 1904 o a3002fad/t2.dat/head//1
2015-11-23 08:48:51.313874 7f6f45b74700 20 osd.0 30 share_map_peer 0x7f6f64eb9440 already has epoch 30
2015-11-23 08:48:51.313896 7f6f45b74700 20 osd.0 30 share_map_peer 0x7f6f65173080 already has epoch 30
2015-11-23 08:48:51.313907 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'3 (0'0,30'3] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] append_log log((0'0,30'3], crt=30'1) [30'4 (30'3) modify   a3002fad/t2.dat/head//1 by client.4141.0:4 2015-11-23 08:48:51.178421]
2015-11-23 08:48:51.313919 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'3 lua=30'3 crt=30'1 lcod 30'2 mlcod 30'2 active+clean] add_log_entry 30'4 (30'3) modify   a3002fad/t2.dat/head//1 by client.4141.0:4 2015-11-23 08:48:51.178421
2015-11-23 08:48:51.313929 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'3 lua=30'3 crt=30'2 lcod 30'2 mlcod 30'2 active+clean] append_log  adding 1 keys
2015-11-23 08:48:51.313936 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'3 lua=30'3 crt=30'2 lcod 30'2 mlcod 30'2 active+clean] append_log: trimming to 30'2 entries 30'2 (30'1) modify   a3002fad/t2.dat/head//1 by client.4141.0:2 2015-11-23 08:48:50.761596
2015-11-23 08:48:51.313951 7f6f45b74700 10 write_log with: dirty_to: 0'0, dirty_from: 4294967295'18446744073709551615, dirty_divergent_priors: 0, writeout_from: 30'4, trimmed: 
2015-11-23 08:48:51.313963 7f6f45b74700  5 filestore(/var/lib/ceph/osd/ceph-0) queue_transactions existing osr(1.2d 0x7f6f64cfdee0)/0x7f6f64cfdee0
2015-11-23 08:48:51.313971 7f6f45b74700 10 journal op_submit_start 2668
2015-11-23 08:48:51.313971 7f6f45b74700  5 filestore(/var/lib/ceph/osd/ceph-0) queue_transactions (writeahead) 2668 0x7f6f65ccda40
2015-11-23 08:48:51.313975 7f6f45b74700 10 journal op_journal_transactions 2668 0x7f6f65ccda40
2015-11-23 08:48:51.313984 7f6f45b74700  5 journal submit_entry seq 2668 len 4196455 (0x7f6f66b58780)
2015-11-23 08:48:51.314000 7f6f45b74700 10 journal op_submit_finish 2668
2015-11-23 08:48:51.314005 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'3 lua=30'3 crt=30'2 lcod 30'2 mlcod 30'2 active+clean] eval_repop repgather(0x7f6f668a7a80 30'4 rep_tid=1904 committed?=0 applied?=0 lock=0 op=osd_op(client.4141.0:4 t2.dat [write 12582912~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) wants=d
2015-11-23 08:48:51.314013 7f6f45b74700 10 osd.0 30 dequeue_op 0x7f6f64d2b200 finish
2015-11-23 08:48:51.316310 7f6f554e2700 20 journal write_thread_entry woke up
2015-11-23 08:48:51.316324 7f6f554e2700 10 journal room 5356097535 max_size 5368709120 pos 40398848 header.start 27791360 top 4096
2015-11-23 08:48:51.316326 7f6f554e2700 10 journal check_for_full at 40398848 : 4202496 < 5356097535
2015-11-23 08:48:51.316327 7f6f554e2700 15 journal prepare_single_write 1 will write 40398848 : seq 2668 len 4196455 -> 4202496 (head 40 pre_pad 4046 ebl 4196455 post_pad 1915 tail 40) (ebl alignment 4086)
2015-11-23 08:48:51.318568 7f6f554e2700 20 journal prepare_multi_write queue_pos now 44601344
2015-11-23 08:48:51.318578 7f6f554e2700 15 journal do_aio_write writing 40398848~4202496
2015-11-23 08:48:51.320187 7f6f554e2700 10 journal align_bl total memcopy: 4202496
2015-11-23 08:48:51.320216 7f6f554e2700 20 journal write_aio_bl 40398848~4202496 seq 2668
2015-11-23 08:48:51.320221 7f6f554e2700 20 journal write_aio_bl .. 40398848~4202496 in 1
2015-11-23 08:48:51.320610 7f6f54ce1700 20 journal write_finish_thread_entry waiting for aio(s)
2015-11-23 08:48:51.320625 7f6f554e2700  5 journal put_throttle finished 1 ops and 4196455 bytes, now 0 ops and 0 bytes
2015-11-23 08:48:51.320629 7f6f554e2700 20 journal write_thread_entry going to sleep
2015-11-23 08:48:51.467301 7f6f574e6700  5 osd.0 30 tick
2015-11-23 08:48:51.467340 7f6f574e6700 20 osd.0 30 scrub_random_backoff lost coin flip, randomly backing off
2015-11-23 08:48:51.467342 7f6f574e6700 10 osd.0 30 do_waiters -- start
2015-11-23 08:48:51.467344 7f6f574e6700 10 osd.0 30 do_waiters -- finish
2015-11-23 08:48:51.475421 7f6f54ce1700 10 journal write_finish_thread_entry aio 40398848~4202496 done
2015-11-23 08:48:51.475462 7f6f54ce1700 20 journal check_aio_completion
2015-11-23 08:48:51.475465 7f6f54ce1700 20 journal check_aio_completion completed seq 2668 40398848~4202496
2015-11-23 08:48:51.475475 7f6f54ce1700 20 journal check_aio_completion queueing finishers through seq 2668
2015-11-23 08:48:51.475482 7f6f54ce1700 10 journal queue_completions_thru seq 2668 queueing seq 2668 0x7f6f66b58780 lat 0.161489
2015-11-23 08:48:51.475515 7f6f54ce1700 20 journal write_finish_thread_entry sleeping
2015-11-23 08:48:51.475524 7f6f544e0700  5 filestore(/var/lib/ceph/osd/ceph-0) _journaled_ahead 0x7f6f657c4050 seq 2668 osr(1.2d 0x7f6f64cfdee0) 0x7f6f65ccda40
2015-11-23 08:48:51.475529 7f6f544e0700  5 filestore(/var/lib/ceph/osd/ceph-0) queue_op 0x7f6f657c4050 seq 2668 osr(1.2d 0x7f6f64cfdee0) 4196441 bytes   (queue has 1 ops and 4196441 bytes)
2015-11-23 08:48:51.475545 7f6f544e0700 10 filestore(/var/lib/ceph/osd/ceph-0)  queueing ondisk 0x7f6f660fb300
2015-11-23 08:48:51.475557 7f6f524dc700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'3 lua=30'3 crt=30'2 lcod 30'2 mlcod 30'2 active+clean] op_commit: 1904
2015-11-23 08:48:51.477846 7f6f3b85d700 10 osd.0 30 handle_replica_op osd_repop_reply(client.4141.0:4 1.2d ondisk, result = 0) v1 epoch 30
2015-11-23 08:48:51.477856 7f6f3b85d700 20 osd.0 30 should_share_map osd.1 10.253.0.4:6801/3119 30
2015-11-23 08:48:51.477869 7f6f3b85d700 15 osd.0 30 enqueue_op 0x7f6f66861800 prio 196 cost 0 latency 0.000239 osd_repop_reply(client.4141.0:4 1.2d ondisk, result = 0) v1
2015-11-23 08:48:51.478069 7f6f3aa4f700 10 osd.0 30 handle_replica_op osd_repop_reply(client.4141.0:4 1.2d ondisk, result = 0) v1 epoch 30
2015-11-23 08:48:51.478077 7f6f3aa4f700 20 osd.0 30 should_share_map osd.2 10.253.0.5:6801/3128 30
2015-11-23 08:48:51.478087 7f6f3aa4f700 15 osd.0 30 enqueue_op 0x7f6f64d2ad00 prio 196 cost 0 latency 0.000136 osd_repop_reply(client.4141.0:4 1.2d ondisk, result = 0) v1
2015-11-23 08:48:51.478133 7f6f45b74700 10 osd.0 30 dequeue_op 0x7f6f66861800 prio 196 cost 0 latency 0.000504 osd_repop_reply(client.4141.0:4 1.2d ondisk, result = 0) v1 pg pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'3 lua=30'3 crt=30'2 lcod 30'2 mlcod 30'2 active+clean]
2015-11-23 08:48:51.478182 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'3 lua=30'3 crt=30'2 lcod 30'2 mlcod 30'2 active+clean] handle_message: 0x7f6f66861800
2015-11-23 08:48:51.478223 7f6f45b74700  7 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'3 lua=30'3 crt=30'2 lcod 30'2 mlcod 30'2 active+clean] sub_op_modify_reply: tid 1904 op  ack_type 4 from 1
2015-11-23 08:48:51.478262 7f6f45b74700 10 osd.0 30 dequeue_op 0x7f6f66861800 finish
2015-11-23 08:48:51.478306 7f6f45b74700 10 osd.0 30 dequeue_op 0x7f6f64d2ad00 prio 196 cost 0 latency 0.000355 osd_repop_reply(client.4141.0:4 1.2d ondisk, result = 0) v1 pg pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'3 lua=30'3 crt=30'2 lcod 30'2 mlcod 30'2 active+clean]
2015-11-23 08:48:51.478331 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'3 lua=30'3 crt=30'2 lcod 30'2 mlcod 30'2 active+clean] handle_message: 0x7f6f64d2ad00
2015-11-23 08:48:51.478356 7f6f45b74700  7 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'3 lua=30'3 crt=30'2 lcod 30'2 mlcod 30'2 active+clean] sub_op_modify_reply: tid 1904 op  ack_type 4 from 2
2015-11-23 08:48:51.478386 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 luod=30'3 lua=30'3 crt=30'2 lcod 30'2 mlcod 30'2 active+clean] repop_all_committed: repop tid 1904 all committed 
2015-11-23 08:48:51.478402 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 lua=30'3 crt=30'2 lcod 30'3 mlcod 30'2 active+clean] eval_repop repgather(0x7f6f668a7a80 30'4 rep_tid=1904 committed?=1 applied?=0 lock=0 op=osd_op(client.4141.0:4 t2.dat [write 12582912~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) wants=d
2015-11-23 08:48:51.478428 7f6f45b74700 15 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 lua=30'3 crt=30'2 lcod 30'3 mlcod 30'2 active+clean] log_op_stats osd_op(client.4141.0:4 t2.dat [write 12582912~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5 inb 4194304 outb 0 rlat 0.000000 lat 0.171036
2015-11-23 08:48:51.478453 7f6f45b74700 15 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 lua=30'3 crt=30'2 lcod 30'3 mlcod 30'2 active+clean] publish_stats_to_osd 30:16
2015-11-23 08:48:51.478469 7f6f45b74700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 lua=30'3 crt=30'2 lcod 30'3 mlcod 30'2 active+clean]  sending commit on repgather(0x7f6f668a7a80 30'4 rep_tid=1904 committed?=1 applied?=0 lock=0 op=osd_op(client.4141.0:4 t2.dat [write 12582912~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) 0x7f6f669bab00
2015-11-23 08:48:51.478531 7f6f45b74700 10 osd.0 30 dequeue_op 0x7f6f64d2ad00 finish
2015-11-23 08:48:51.479045 7f6f53cdf700 10 journal op_apply_start 2668 open_ops 0 -> 1
2015-11-23 08:48:51.479061 7f6f53cdf700  5 filestore(/var/lib/ceph/osd/ceph-0) _do_op 0x7f6f657c4050 seq 2668 osr(1.2d 0x7f6f64cfdee0)/0x7f6f64cfdee0 start
2015-11-23 08:48:51.479072 7f6f53cdf700 10 filestore(/var/lib/ceph/osd/ceph-0) _do_transaction on 0x7f6f65ccda40
2015-11-23 08:48:51.479099 7f6f53cdf700 15 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1
2015-11-23 08:48:51.479190 7f6f53cdf700 10 filestore oid: 2d//head//1 not skipping op, *spos 2668.0.0
2015-11-23 08:48:51.479194 7f6f53cdf700 10 filestore  > header.spos 0.0.0
2015-11-23 08:48:51.479296 7f6f53cdf700 20 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1 = 0
2015-11-23 08:48:51.479310 7f6f53cdf700 15 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1
2015-11-23 08:48:51.479345 7f6f53cdf700 10 filestore oid: 2d//head//1 not skipping op, *spos 2668.0.1
2015-11-23 08:48:51.479348 7f6f53cdf700 10 filestore  > header.spos 0.0.0
2015-11-23 08:48:51.479392 7f6f53cdf700 20 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1 = 0
2015-11-23 08:48:51.479404 7f6f53cdf700 15 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1
2015-11-23 08:48:51.479433 7f6f53cdf700 10 filestore oid: 2d//head//1 not skipping op, *spos 2668.0.2
2015-11-23 08:48:51.479436 7f6f53cdf700 10 filestore  > header.spos 0.0.0
2015-11-23 08:48:51.479485 7f6f53cdf700 20 filestore(/var/lib/ceph/osd/ceph-0) _omap_setkeys 1.2d_head/2d//head//1 = 0
2015-11-23 08:48:51.479493 7f6f53cdf700 15 filestore(/var/lib/ceph/osd/ceph-0) write 1.2d_head/a3002fad/t2.dat/head//1 12582912~4194304
2015-11-23 08:48:51.486162 7f6f4fb88700  1 osd.0 30 ms_handle_reset con 0x7f6f66884680 session 0x7f6f66772a00
2015-11-23 08:48:51.486975 7f6f53cdf700 10 filestore(/var/lib/ceph/osd/ceph-0) write 1.2d_head/a3002fad/t2.dat/head//1 12582912~4194304 = 4194304
2015-11-23 08:48:51.487097 7f6f53cdf700 20 filestore(/var/lib/ceph/osd/ceph-0) fgetattrs 145 getting '_'
2015-11-23 08:48:51.487113 7f6f53cdf700 20 filestore(/var/lib/ceph/osd/ceph-0) fgetattrs 145 getting 'snapset'
2015-11-23 08:48:51.487121 7f6f53cdf700 15 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1
2015-11-23 08:48:51.487174 7f6f53cdf700 10 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1 = 0
2015-11-23 08:48:51.487203 7f6f53cdf700 20 filestore(/var/lib/ceph/osd/ceph-0) fgetattrs 145 getting '_'
2015-11-23 08:48:51.487383 7f6f53cdf700 20 filestore(/var/lib/ceph/osd/ceph-0) fgetattrs 145 getting 'snapset'
2015-11-23 08:48:51.487444 7f6f53cdf700 15 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1
2015-11-23 08:48:51.487479 7f6f53cdf700 10 filestore(/var/lib/ceph/osd/ceph-0) setattrs 1.2d_head/a3002fad/t2.dat/head//1 = 0
2015-11-23 08:48:51.487492 7f6f53cdf700 10 journal op_apply_finish 2668 open_ops 1 -> 0, max_applied_seq 2667 -> 2668
2015-11-23 08:48:51.487670 7f6f53cdf700 10 filestore(/var/lib/ceph/osd/ceph-0) _do_op 0x7f6f657c4050 seq 2668 r = 0, finisher 0x7f6f660fa400 0x7f6f66264840
2015-11-23 08:48:51.487680 7f6f53cdf700 10 filestore(/var/lib/ceph/osd/ceph-0) _finish_op 0x7f6f657c4050 seq 2668 osr(1.2d 0x7f6f64cfdee0)/0x7f6f64cfdee0
2015-11-23 08:48:51.487788 7f6f52cdd700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 lua=30'3 crt=30'2 lcod 30'3 mlcod 30'2 active+clean] op_applied: 1904
2015-11-23 08:48:51.487861 7f6f52cdd700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 lua=30'3 crt=30'2 lcod 30'3 mlcod 30'2 active+clean] op_applied version 30'4
2015-11-23 08:48:51.487881 7f6f52cdd700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'2 lcod 30'3 mlcod 30'2 active+clean] repop_all_applied: repop tid 1904 all applied 
2015-11-23 08:48:51.487896 7f6f52cdd700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'2 lcod 30'3 mlcod 30'2 active+clean] eval_repop repgather(0x7f6f668a7a80 30'4 rep_tid=1904 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:4 t2.dat [write 12582912~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5) wants=d
2015-11-23 08:48:51.487924 7f6f52cdd700 15 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'2 lcod 30'3 mlcod 30'2 active+clean] publish_stats_to_osd 30: no change since
2015-11-23 08:48:51.487986 7f6f52cdd700 15 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'2 lcod 30'3 mlcod 30'2 active+clean] do_osd_op_effects client.4141 con 0x7f6f66884680
2015-11-23 08:48:51.487992 7f6f52cdd700 10 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'2 lcod 30'3 mlcod 30'3 active+clean]  removing repgather(0x7f6f668a7a80 30'4 rep_tid=1904 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:4 t2.dat [write 12582912~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5)
2015-11-23 08:48:51.487997 7f6f52cdd700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'2 lcod 30'3 mlcod 30'3 active+clean]    q front is repgather(0x7f6f668a7a80 30'4 rep_tid=1904 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:4 t2.dat [write 12582912~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5)
2015-11-23 08:48:51.488003 7f6f52cdd700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'2 lcod 30'3 mlcod 30'3 active+clean] remove_repop repgather(0x7f6f668a7a80 30'4 rep_tid=1904 committed?=1 applied?=1 lock=0 op=osd_op(client.4141.0:4 t2.dat [write 12582912~4194304] 1.a3002fad ondisk+write+known_if_redirected e30) v5)
2015-11-23 08:48:51.488008 7f6f52cdd700 20 osd.0 pg_epoch: 30 pg[1.2d( v 30'4 (0'0,30'4] local-les=15 n=1 ec=14 les/c 15/27 14/14/14) [0,1,2] r=0 lpr=14 crt=30'2 lcod 30'3 mlcod 30'3 active+clean]  obc obc(a3002fad/t2.dat/head//1 rwstate(write n=1 w=0))
2015-11-23 08:48:52.160044 7f6f4a37d700 20 osd.0 30 share_map_peer 0x7f6f64eb9440 already has epoch 30
2015-11-23 08:48:52.160063 7f6f4bb80700 20 osd.0 30 share_map_peer 0x7f6f64eb9440 already has epoch 30
2015-11-23 08:48:52.467657 7f6f574e6700  5 osd.0 30 tick
2015-11-23 08:48:52.467717 7f6f574e6700 20 osd.0 30 scrub_random_backoff lost coin flip, randomly backing off
2015-11-23 08:48:52.467722 7f6f574e6700 10 osd.0 30 do_waiters -- start
2015-11-23 08:48:52.467725 7f6f574e6700 10 osd.0 30 do_waiters -- finish
2015-11-23 08:48:53.329800 7f6f4bb80700 20 osd.0 30 share_map_peer 0x7f6f65173080 already has epoch 30
2015-11-23 08:48:53.329818 7f6f4a37d700 20 osd.0 30 share_map_peer 0x7f6f65173080 already has epoch 30
2015-11-23 08:48:53.468049 7f6f574e6700  5 osd.0 30 tick
2015-11-23 08:48:53.468112 7f6f574e6700 20 osd.0 30 scrub_should_schedule should run between 0 - 24 now 8 = yes
2015-11-23 08:48:53.468277 7f6f574e6700 20 osd.0 30 scrub_should_schedule loadavg 0 < max 0.5 = yes
2015-11-23 08:48:53.468305 7f6f574e6700 20 osd.0 30 sched_scrub load_is_low=1
2015-11-23 08:48:53.468310 7f6f574e6700 10 osd.0 30 sched_scrub 0.0 at 2015-11-22 14:30:18.368406: 65915.1 < min (86400 seconds)
2015-11-23 08:48:53.468332 7f6f574e6700 20 osd.0 30 sched_scrub done
2015-11-23 08:48:53.468337 7f6f574e6700 10 osd.0 30 do_waiters -- start
2015-11-23 08:48:53.468341 7f6f574e6700 10 osd.0 30 do_waiters -- finish
2015-11-23 08:48:54.468777 7f6f574e6700  5 osd.0 30 tick
2015-11-23 08:48:54.468828 7f6f574e6700  7 osd.0 30 do_mon_report
2015-11-23 08:48:54.468833 7f6f574e6700 10 osd.0 30 send_alive up_thru currently 22 want 17
2015-11-23 08:48:54.468839 7f6f574e6700 20 osd.0 30 send_pg_stats
2015-11-23 08:48:54.468847 7f6f574e6700 10 osd.0 30 send_pg_stats - 1 pgs updated
2015-11-23 08:48:54.468913 7f6f574e6700 20 osd.0 30 scrub_random_backoff lost coin flip, randomly backing off
2015-11-23 08:48:54.468918 7f6f574e6700 10 osd.0 30 do_waiters -- start
2015-11-23 08:48:54.468921 7f6f574e6700 10 osd.0 30 do_waiters -- finish
2015-11-23 08:48:54.852773 7f6f4fb88700 10 osd.0 30 do_waiters -- start
2015-11-23 08:48:54.852774 7f6f4fb88700 10 osd.0 30 do_waiters -- finish
2015-11-23 08:48:54.852776 7f6f4fb88700 20 osd.0 30 _dispatch 0x7f6f6699f000 pg_stats_ack(1 pgs tid 2881) v1
2015-11-23 08:48:54.852777 7f6f4fb88700 10 osd.0 30 handle_pg_stats_ack 
2015-11-23 08:48:54.852781 7f6f4fb88700 10 osd.0 30 do_waiters -- start
2015-11-23 08:48:54.852781 7f6f4fb88700 10 osd.0 30 do_waiters -- finish
2015-11-23 08:48:55.421627 7f6f3f367700 20 osd.0 30 update_osd_stat osd_stat(71492 kB used, 255 GB avail, 255 GB total, peers [1,2]/[] op hist [])
2015-11-23 08:48:55.421648 7f6f3f367700  5 osd.0 30 heartbeat: osd_stat(71492 kB used, 255 GB avail, 255 GB total, peers [1,2]/[] op hist [])
2015-11-23 08:48:55.422107 7f6f4cb82700 20 osd.0 30 share_map_peer 0x7f6f64eb9440 already has epoch 30
2015-11-23 08:48:55.422116 7f6f4cb82700 20 osd.0 30 share_map_peer 0x7f6f65173080 already has epoch 30
2015-11-23 08:48:55.422122 7f6f4cb82700 20 osd.0 30 share_map_peer 0x7f6f65173080 already has epoch 30
2015-11-23 08:48:55.422318 7f6f4cb82700 20 osd.0 30 share_map_peer 0x7f6f64eb9440 already has epoch 30
2015-11-23 08:48:55.469153 7f6f574e6700  5 osd.0 30 tick
2015-11-23 08:48:55.469213 7f6f574e6700 20 osd.0 30 scrub_random_backoff lost coin flip, randomly backing off
2015-11-23 08:48:55.469218 7f6f574e6700 10 osd.0 30 do_waiters -- start
2015-11-23 08:48:55.469221 7f6f574e6700 10 osd.0 30 do_waiters -- finish
2015-11-23 08:48:55.904337 7f6f55ce3700 20 filestore(/var/lib/ceph/osd/ceph-0) sync_entry woke after 5.000175
2015-11-23 08:48:55.904378 7f6f55ce3700 10 journal commit_start max_applied_seq 2668, open_ops 0
2015-11-23 08:48:55.904381 7f6f55ce3700 10 journal commit_start blocked, all open_ops have completed
2015-11-23 08:48:55.904383 7f6f55ce3700 10 journal commit_start committing 2668, still blocked
2015-11-23 08:48:55.904385 7f6f55ce3700 10 journal commit_start
2015-11-23 08:48:55.904391 7f6f55ce3700 15 filestore(/var/lib/ceph/osd/ceph-0) sync_entry committing 2668
2015-11-23 08:48:55.904394 7f6f55ce3700 10 journal commit_started committing 2668, unblocking
2015-11-23 08:48:55.904398 7f6f55ce3700 15 genericfilestorebackend(/var/lib/ceph/osd/ceph-0) syncfs: doing a full sync (syncfs(2) if possible)
2015-11-23 08:48:56.148439 7f6f55ce3700 10 filestore(/var/lib/ceph/osd/ceph-0) sync_entry commit took 0.244049, interval was 5.244275
2015-11-23 08:48:56.148488 7f6f55ce3700 10 journal commit_finish thru 2668
2015-11-23 08:48:56.148494 7f6f55ce3700  5 journal committed_thru 2668 (last_committed_seq 2664)
2015-11-23 08:48:56.148501 7f6f55ce3700 10 journal header: block_size 4096 alignment 4096 max_size 5368709120
2015-11-23 08:48:56.148504 7f6f55ce3700 10 journal header: start 44601344
2015-11-23 08:48:56.148506 7f6f55ce3700 10 journal  write_pos 44601344
2015-11-23 08:48:56.148509 7f6f55ce3700 10 journal committed_thru done
2015-11-23 08:48:56.148555 7f6f55ce3700 15 filestore(/var/lib/ceph/osd/ceph-0) sync_entry committed to op_seq 2668
2015-11-23 08:48:56.148566 7f6f55ce3700 20 filestore(/var/lib/ceph/osd/ceph-0) sync_entry waiting for max_interval 5.000000
2015-11-23 08:48:56.469533 7f6f574e6700  5 osd.0 30 tick
2015-11-23 08:48:56.469592 7f6f574e6700 20 osd.0 30 scrub_random_backoff lost coin flip, randomly backing off
2015-11-23 08:48:56.469597 7f6f574e6700 10 osd.0 30 do_waiters -- start
2015-11-23 08:48:56.469601 7f6f574e6700 10 osd.0 30 do_waiters -- finish
2015-11-23 08:48:56.521921 7f6f3f367700 20 osd.0 30 update_osd_stat osd_stat(71320 kB used, 255 GB avail, 255 GB total, peers [1,2]/[] op hist [])
2015-11-23 08:48:56.521937 7f6f3f367700  5 osd.0 30 heartbeat: osd_stat(71320 kB used, 255 GB avail, 255 GB total, peers [1,2]/[] op hist [])
2015-11-23 08:48:56.522402 7f6f4cb82700 20 osd.0 30 share_map_peer 0x7f6f64eb9440 already has epoch 30
2015-11-23 08:48:56.522412 7f6f4cb82700 20 osd.0 30 share_map_peer 0x7f6f64eb9440 already has epoch 30
2015-11-23 08:48:56.522447 7f6f4cb82700 20 osd.0 30 share_map_peer 0x7f6f65173080 already has epoch 30
2015-11-23 08:48:56.522453 7f6f4cb82700 20 osd.0 30 share_map_peer 0x7f6f65173080 already has epoch 30
